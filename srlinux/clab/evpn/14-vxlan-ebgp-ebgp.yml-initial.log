[WARNING]: Could not match supplied host pattern, ignoring: unprovisioned

PLAY [Deploy initial device configuration] *************************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [spine]
ok: [l1]
ok: [l2]
ok: [h1]
ok: [h2]

TASK [Find device readiness script] ********************************************
ok: [spine]
ok: [l1]
ok: [l2]
ok: [h1]
ok: [h2]

TASK [Wait for device to become ready] *****************************************
skipping: [spine]
skipping: [l1]
skipping: [l2]
skipping: [h1]
skipping: [h2]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for spine, l1, l2, h1, h2

TASK [Figure out whether to deploy the module initial on current device] *******
ok: [spine]
ok: [l1]
ok: [l2]
ok: [h1]
ok: [h2]

TASK [Find configuration template for initial] *********************************
ok: [spine]
ok: [l1]
ok: [l2]
ok: [h1]
ok: [h2]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [spine] => 
  msg: |-
    initial configuration for spine
    =========================================
  
    updates:
  
    - path: /interface[name=system0]/subinterface[index=0]
      value:
       description: "No description"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.0.0.1/32"
  
  
    - path: /interface[name=ethernet-1/1]
      value:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
       mtu: 1614
       subinterface:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
        ip-mtu: 1600
        index: 0
        description: "spine ~ l1"
  
    - path: /interface[name=ethernet-1/1]/subinterface[index=0]
      value:
       description: "spine ~ l1"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.1.0.2/30"
          primary: [null]
  
    - path: /interface[name=ethernet-1/2]
      value:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
       mtu: 1614
       subinterface:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
        ip-mtu: 1600
        index: 0
        description: "spine ~ l2"
  
    - path: /interface[name=ethernet-1/2]/subinterface[index=0]
      value:
       description: "spine ~ l2"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.1.0.6/30"
          primary: [null]
  
  
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: system0.0
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: ethernet-1/1.0
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: ethernet-1/2.0
ok: [l1] => 
  msg: |-
    initial configuration for l1
    =========================================
  
    updates:
  
    - path: /interface[name=system0]/subinterface[index=0]
      value:
       description: "No description"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.0.0.2/32"
  
  
    - path: /interface[name=ethernet-1/1]
      value:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
       mtu: 1614
       subinterface:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
        ip-mtu: 1600
        index: 0
        description: "l1 ~ spine"
  
    - path: /interface[name=ethernet-1/1]/subinterface[index=0]
      value:
       description: "l1 ~ spine"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.1.0.1/30"
          primary: [null]
  
  
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: system0.0
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: ethernet-1/1.0
ok: [l2] => 
  msg: |-
    initial configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    sysctl -qw net.ipv6.conf.eth2.disable_ipv6=1
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1600
    ip link set eth2 mtu 1500
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname l2
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.3/32
    !
    interface eth1
     no shutdown
     description l2 -> spine [external]
     ip address 10.1.0.5/30
    !
    interface eth2
     no shutdown
     description [Access VLAN red] l2 -> h2
     ! no ip address
    !
    interface vlan1000
     no shutdown
     description VLAN red (1000) -> [h1,l1,h2]
     ! no ip address
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [h1] => 
  msg: |-
    initial configuration for h1
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.31.1.4/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.31.1.4/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    #
    # Print the final routing table
    ip route
ok: [h2] => 
  msg: |-
    initial configuration for h2
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.31.1.5/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.31.1.5/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    #
    # Print the final routing table
    ip route

TASK [Find configuration deployment deploy_script for initial] *****************
ok: [spine]
ok: [l1]
ok: [l2]
ok: [h1]
ok: [h2]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for spine, l1
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/initial-clab.yml for l2
included: /home/pipi/net101/tools/netsim/ansible/tasks/linux/initial-clab.yml for h1, h2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [spine]
ok: [l1]

TASK [Update SRL initial node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/initial/srlinux.j2)] ***
changed: [spine]
changed: [l1]

TASK [debug] *******************************************************************
skipping: [spine]
skipping: [l1]

TASK [Attempt to load VRF kernel module] ***************************************
changed: [l2 -> localhost]

TASK [Disable FRR management VRF when modprobe fails] **************************
skipping: [l2]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for l2

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
changed: [l2]

TASK [run vtysh to import initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
skipping: [l2]

TASK [set_fact] ****************************************************************
ok: [h1]
ok: [h2]

TASK [Create initial container setup from /home/pipi/net101/tools/netsim/ansible/templates/initial/linux-clab.j2] ***
changed: [h2 -> localhost]
changed: [h1 -> localhost]

TASK [Initial container configuration via /tmp/config-aOacCbYF-h1.sh] **********
changed: [h2 -> localhost]
changed: [h1 -> localhost]

TASK [file] ********************************************************************
changed: [h2 -> localhost]
changed: [h1 -> localhost]

PLAY [Deploy module-specific configurations] ***********************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Deploy individual configuration modules] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=vlan)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=bgp)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=vxlan)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=evpn)

TASK [Figure out whether to deploy the module vlan on current device] **********
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for vlan] ************************************
skipping: [spine]
ok: [l1]
ok: [l2]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [spine]
ok: [l2] => 
  msg: |-
    vlan configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
    if [ ! -e /sys/devices/virtual/net/vlan1000 ]; then
      brctl addbr vlan1000
  
  
      ip link set dev vlan1000 up
      ip addr flush dev vlan1000
    fi
  
    brctl addif vlan1000 eth2
    exit 0
ok: [l1] => 
  msg: |-
    vlan configuration for l1
    =========================================
  
    updates:
    - path: /interface[name=ethernet-1/2]
      value:
       subinterface:
       - index: 1000
         type: bridged
         description: "Access VLAN red l1 ~ h1"
  
  
    - path: /network-instance[name=vlan1000]
      value:
       type: mac-vrf
       description: "Access VLAN red l1 ~ h1"
       interface:
       - name: ethernet-1/2.1000
  
  
    - path: /interface[name=irb0]
      value:
       subinterface:
       - index: 1000

TASK [Find configuration deployment deploy_script for vlan] ********************
skipping: [spine]
ok: [l1]
ok: [l2]

TASK [Deploy vlan configuration] ***********************************************
skipping: [spine]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]

TASK [Update SRL vlan node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/vlan/srlinux.j2)] ***
changed: [l1]

TASK [debug] *******************************************************************
skipping: [l1]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy vlan config from /home/pipi/net101/tools/netsim/ansible/templates/vlan/frr.j2] ***
changed: [l2]

TASK [run vtysh to import vlan config from /home/pipi/net101/tools/netsim/ansible/templates/vlan/frr.j2] ***
skipping: [l2]

TASK [Figure out whether to deploy the module bgp on current device] ***********
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for bgp] *************************************
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l2] => 
  msg: |-
    bgp configuration for l2
    =========================================
    !
    router bgp 65201
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.3
    !
      neighbor 10.1.0.6 remote-as 65100
      neighbor 10.1.0.6 description spine
    !
      neighbor 10.0.0.1 remote-as 65100
      neighbor 10.0.0.1 description spine
      neighbor 10.0.0.1 update-source lo
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.3/32
    !
    !
    !
      neighbor 10.1.0.6 activate
      no neighbor 10.1.0.6 send-community all
      neighbor 10.1.0.6 send-community standard
      neighbor 10.1.0.6 send-community large
      neighbor 10.1.0.6 send-community extended
    !
    !
    !
    do write
ok: [l1] => 
  msg: |-
    bgp configuration for l1
    =========================================
    updates:
  
    - path: /routing-policy/policy[name=accept_all]
      value:
        default-action:
          policy-result: accept
  
    - path: /routing-policy/community-set[name=ibgp-mark]
      value:
        member: [ "65536:0:65536" ]
  
    - path: /routing-policy/policy[name=ibgp-mark]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: mark-ibgp-routes
          action:
            bgp:
              communities:
                add: ibgp-mark
            policy-result: accept
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix: [] # Make sure it exists
  
    - path: /routing-policy/policy[name=default_bgp_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
            prefix-set: default_bgp_advertise
          action:
            policy-result: next-policy
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: next-policy
            bgp:
              communities:
                remove:
                  ibgp-mark
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        admin-state: enable
        autonomous-system: 65200
        router-id: 10.0.0.2
        ebgp-default-policy:
          export-reject-all: False
          import-reject-all: False
  
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix:
        - ip-prefix: 10.0.0.2/32
          mask-length-range: exact
  
  
  
  
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ebgp]
      value:
        admin-state: enable
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.1.0.2"
          description: spine
          peer-group: ebgp
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: enable
  
          peer-as: 65100
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ebgp]
      value:
        admin-state: enable
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: evpn
          admin-state: enable
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.0.0.1"
          description: spine
          peer-group: ebgp
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: disable
          - afi-safi-name: evpn
            admin-state: enable
  
          peer-as: 65100
ok: [spine] => 
  msg: |-
    bgp configuration for spine
    =========================================
    updates:
  
    - path: /routing-policy/policy[name=accept_all]
      value:
        default-action:
          policy-result: accept
  
    - path: /routing-policy/community-set[name=ibgp-mark]
      value:
        member: [ "65536:0:65536" ]
  
    - path: /routing-policy/policy[name=ibgp-mark]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: mark-ibgp-routes
          action:
            bgp:
              communities:
                add: ibgp-mark
            policy-result: accept
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix: [] # Make sure it exists
  
    - path: /routing-policy/policy[name=default_bgp_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
            prefix-set: default_bgp_advertise
          action:
            policy-result: next-policy
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: next-policy
            bgp:
              communities:
                remove:
                  ibgp-mark
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        admin-state: enable
        autonomous-system: 65100
        router-id: 10.0.0.1
        ebgp-default-policy:
          export-reject-all: False
          import-reject-all: False
  
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix:
        - ip-prefix: 10.0.0.1/32
          mask-length-range: exact
  
  
  
  
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ebgp]
      value:
        admin-state: enable
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.1.0.1"
          description: l1
          peer-group: ebgp
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: enable
  
          peer-as: 65200
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ebgp]
      value:
        admin-state: enable
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.1.0.5"
          description: l2
          peer-group: ebgp
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: enable
  
          peer-as: 65201
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ebgp]
      value:
        admin-state: enable
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: evpn
          admin-state: enable
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.0.0.2"
          description: l1
          peer-group: ebgp
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: disable
          - afi-safi-name: evpn
            admin-state: enable
  
          peer-as: 65200
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ebgp]
      value:
        admin-state: enable
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: evpn
          admin-state: enable
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.0.0.3"
          description: l2
          peer-group: ebgp
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: disable
          - afi-safi-name: evpn
            admin-state: enable
  
          peer-as: 65201

TASK [Find configuration deployment deploy_script for bgp] *********************
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Deploy bgp configuration] ************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL bgp node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/bgp/srlinux.j2)] ***
changed: [l1]
changed: [spine]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
skipping: [l2]

TASK [run vtysh to import bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
changed: [l2]

TASK [Figure out whether to deploy the module vxlan on current device] *********
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for vxlan] ***********************************
skipping: [spine]
ok: [l1]
ok: [l2]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [spine]
ok: [l1] => 
  msg: |-
    vxlan configuration for l1
    =========================================
  
    updates:
    - path: /tunnel-interface[name=vxlan0]/vxlan-interface[index=1000]
      value:
       type: bridged
       ingress:
        vni: 1000
       egress:
        source-ip: use-system-ipv4-address
  
    - path: /network-instance[name=vlan1000]
      value:
       type: mac-vrf
       vxlan-interface:
       - name: vxlan0.1000
       protocols:
        bgp-vpn:
         bgp-instance:
         - id: 1
           # route-distinguisher:
           # rd: "10.0.0.2:1000"
           _annotate: "RD left as <auto> for EVPN services and ECMP to work as expected, not '10.0.0.2:1000'"
           route-target:
            _annotate: "For compatibility with frr, override auto-derived RT based on EVI 1000 with VNI 1000"
            import-rt: "target:65000:1000"
            export-rt: "target:65000:1000"
        bgp-evpn:
         bgp-instance:
         - id: 1
           evi: 1000
           ecmp: 8
           vxlan-interface: vxlan0.1000
ok: [l2] => 
  msg: |-
    vxlan configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
  
  
  
    # Determine max MTU used on interfaces, to configure VXLAN interface
  
    # Create L3 VNIs with bridges and add to correct vrf table
  
    # Create VXLAN L2 interface per vni
    ip link add vxlan1000 type vxlan \
      id 1000 \
      dstport 4789 \
      local 10.0.0.3 nolearning
    #
    # Add it to the VLAN bridge (create if needed for l3 vnis); disable STP
    if [ ! -e /sys/devices/virtual/net/vlan1000 ]; then
    brctl addbr vlan1000
    ip link set up dev vlan1000
    fi
    brctl addif vlan1000 vxlan1000
    brctl stp vlan1000 off
    # Do not generate ipv6 link-local address for VXLAN devices
    ip link set mtu 1600 addrgenmode none dev vxlan1000
    # Disable dynamic MAC learning for evpn, see https://docs.frrouting.org/en/latest/evpn.html
    bridge link set dev vxlan1000 learning off
    ip link set up dev vxlan1000
  
  
    exit $?

TASK [Find configuration deployment deploy_script for vxlan] *******************
skipping: [spine]
ok: [l1]
ok: [l2]

TASK [Deploy vxlan configuration] **********************************************
skipping: [spine]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]

TASK [Update SRL vxlan node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/vxlan/srlinux.j2)] ***
changed: [l1]

TASK [debug] *******************************************************************
skipping: [l1]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy vxlan config from /home/pipi/net101/tools/netsim/ansible/templates/vxlan/frr.j2] ***
changed: [l2]

TASK [run vtysh to import vxlan config from /home/pipi/net101/tools/netsim/ansible/templates/vxlan/frr.j2] ***
skipping: [l2]

TASK [Figure out whether to deploy the module evpn on current device] **********
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for evpn] ************************************
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l1] => 
  msg: |-
    evpn configuration for l1
    =========================================
  
  
    updates:
    - path: /network-instance[name=default]/protocols/bgp
      value:
        group:
        - group-name: ebgp # Could create a dedicated group for EVPN only?
          afi-safi:
          - afi-safi-name: evpn
            admin-state: enable
        route-advertisement:
          rapid-withdrawal: True
        afi-safi:
        - afi-safi-name: evpn
          evpn:
            rapid-update: True
            inter-as-vpn: True
ok: [l2] => 
  msg: |-
    evpn configuration for l2
    =========================================
    router bgp 65201
     address-family l2vpn evpn
      advertise-all-vni
      advertise-svi-ip
      advertise ipv4 unicast
  
    ! Configure explicit Route Targets and RD per L2 VNI; auto-derived differs
      vni 1000
       rd 10.0.0.3:1000
       route-target export 65000:1000
       route-target import 65000:1000
      exit-vni
  
      neighbor 10.0.0.1 activate
      neighbor 10.0.0.1 soft-reconfiguration inbound
  
     exit-address-family
    !
  
    exit
  
    ! L3 VRF EVPN handling
    !
    do write
ok: [spine] => 
  msg: |-
    evpn configuration for spine
    =========================================
  
  
    updates:
    - path: /network-instance[name=default]/protocols/bgp
      value:
        group:
        - group-name: ebgp # Could create a dedicated group for EVPN only?
          afi-safi:
          - afi-safi-name: evpn
            admin-state: enable
        route-advertisement:
          rapid-withdrawal: True
        afi-safi:
        - afi-safi-name: evpn
          evpn:
            rapid-update: True
            inter-as-vpn: True

TASK [Find configuration deployment deploy_script for evpn] ********************
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Deploy evpn configuration] ***********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL evpn node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/evpn/srlinux.j2)] ***
changed: [spine]
changed: [l1]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy evpn config from /home/pipi/net101/tools/netsim/ansible/templates/evpn/frr.j2] ***
skipping: [l2]

TASK [run vtysh to import evpn config from /home/pipi/net101/tools/netsim/ansible/templates/evpn/frr.j2] ***
changed: [l2]

PLAY [Deploy custom deployment templates] **************************************

TASK [Run custom configuration deployment scripts] *****************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-custom-config.yml for l1, l2, spine => (item=ebgp.multihop)

TASK [Find configuration template] *********************************************
ok: [l1]
ok: [l2]
ok: [spine]

TASK [fail] ********************************************************************
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Check is the configuration template is a file] ***************************
ok: [l1 -> localhost]
ok: [l2 -> localhost]
ok: [spine -> localhost]

TASK [fail] ********************************************************************
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Process template /home/pipi/net101/tools/netsim/extra/ebgp.multihop/srlinux.j2 for l1] ***
skipping: [l2]
skipping: [l1]
skipping: [spine]

TASK [Find custom configuration deployment script] *****************************
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Run the configuration deployment script] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL ebgp.multihop node configuration (template=/home/pipi/net101/tools/netsim/extra/ebgp.multihop/srlinux.j2)] ***
changed: [l1]
changed: [spine]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy ebgp.multihop config from /home/pipi/net101/tools/netsim/extra/ebgp.multihop/frr.j2] ***
skipping: [l2]

TASK [run vtysh to import ebgp.multihop config from /home/pipi/net101/tools/netsim/extra/ebgp.multihop/frr.j2] ***
changed: [l2]

PLAY RECAP *********************************************************************
h1                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
h2                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
l1                         : ok=50   changed=6    unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
l2                         : ok=58   changed=13   unreachable=0    failed=0    skipped=11   rescued=0    ignored=0   
spine                      : ok=38   changed=4    unreachable=0    failed=0    skipped=16   rescued=0    ignored=0   



The devices under test are EVPN switches (leaf and spine) using
EVPN-over-multihop-EBGP. The leaf switch should generate and accept EVPN AF
routes, and the spine switch should propagate them without changing the BGP
next hop.

* h1 and h2 should be able to ping each other

Please note it might take a while for the lab to work due to
STP learning phase

