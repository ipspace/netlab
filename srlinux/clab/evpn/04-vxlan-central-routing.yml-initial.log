/home/pipi/.local/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
  "cipher": algorithms.TripleDES,
/home/pipi/.local/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
  "class": algorithms.TripleDES,
[WARNING]: Could not match supplied host pattern, ignoring: unprovisioned
[WARNING]: Found variable using reserved name: hosts

PLAY [Deploy initial device configuration] *************************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find device readiness script] ********************************************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Wait for device to become ready] *****************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Normalize config on bridge-like devices] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine

TASK [Figure out whether to deploy the module normalize on current device] *****
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for normalize] *******************************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [spine]
ok: [l2]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for normalize] ***************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [spine]
ok: [l2]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Deploy normalize configuration] ******************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine

TASK [Figure out whether to deploy the module initial on current device] *******
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for initial] *********************************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for initial] *****************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [spine]
ok: [l2]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [h1] => 
  msg: |-
    initial configuration for h1
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
  
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Send ARP requests from a sane source IP address
    sysctl -w net.ipv4.conf.all.arp_announce=2
  
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
  
    #
    # Interface addressing, create any bond devices
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.0.1/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.0.1/24 dev eth1
    sysctl -w net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
ok: [h2] => 
  msg: |-
    initial configuration for h2
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
  
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Send ARP requests from a sane source IP address
    sysctl -w net.ipv4.conf.all.arp_announce=2
  
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
  
    #
    # Interface addressing, create any bond devices
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.0.2/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.0.2/24 dev eth1
    sysctl -w net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
ok: [h3] => 
  msg: |-
    initial configuration for h3
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
  
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Send ARP requests from a sane source IP address
    sysctl -w net.ipv4.conf.all.arp_announce=2
  
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
  
    #
    # Interface addressing, create any bond devices
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.1.3/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.1.3/24 dev eth1
    sysctl -w net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
ok: [h4] => 
  msg: |-
    initial configuration for h4
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
  
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Send ARP requests from a sane source IP address
    sysctl -w net.ipv4.conf.all.arp_announce=2
  
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
  
    #
    # Interface addressing, create any bond devices
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.1.4/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.1.4/24 dev eth1
    sysctl -w net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
ok: [l2] => 
  msg: |-
    initial configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # This is an artifact of unknown provenance that should be removed in a year or two (= 2026/2027)
    #
    # FRR controls these parameters with 'ip forwarding' and 'ipv6 forwarding' commands
    #
    sysctl -w net.ipv4.ip_forward=1
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    # Set system defaults
    #
    # Send ARP requests from a sane source IP address
    #
    sysctl -w net.ipv4.conf.all.arp_announce=2
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    ip link set eth1 down
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1600
    ip link set eth1 up
    ip link set eth2 down
    sysctl -qw net.ipv6.conf.eth2.disable_ipv6=1
    ip link set dev eth2 mtu 1500
    ip link set eth2 up
    ip link set eth3 down
    sysctl -qw net.ipv6.conf.eth3.disable_ipv6=1
    ip link set dev eth3 mtu 1500
    ip link set eth3 up
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname l2
    !
    !
    ip forwarding
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.6/32
    !
    interface eth1
     no shutdown
     description l2 -> spine
     ip address 10.1.0.5/30
    !
    interface eth2
     no shutdown
     description [Access VLAN red] l2 -> h2
     ! no ip address
    !
    interface eth3
     no shutdown
     description [Access VLAN blue] l2 -> h4
     ! no ip address
    !
    interface vlan1000
     no shutdown
     description VLAN red (1000) -> [h1,l1,h2,spine] [external]
     ! no ip address
    !
    interface vlan1001
     no shutdown
     description VLAN blue (1001) -> [h3,l1,h4,spine] [external]
     ! no ip address
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    !
    exit 0
ok: [l1] => 
  msg: |-
    initial configuration for l1
    =========================================
  
    updates:
  
    - path: /interface[name=system0]/subinterface[index=0]
      value:
       description: "No description"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.0.0.5/32"
  
    - path: /interface[name=ethernet-1/1]
      value:
       description: "l1 ~ spine"
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
       mtu: 1614
       subinterface:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
        ip-mtu: 1600
        index: 0
        description: "l1 ~ spine"
  
    - path: /interface[name=ethernet-1/1]/subinterface[index=0]
      value:
       description: "l1 ~ spine"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.1.0.1/30"
          primary: [null]
  
  
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: system0.0
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: ethernet-1/1.0
  
  
  
    # TODO: vdata.rd, vdata.import/export, vdata.af
ok: [spine] => 
  msg: |-
    initial configuration for spine
    =========================================
  
    updates:
  
    - path: /interface[name=system0]/subinterface[index=0]
      value:
       description: "No description"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.0.0.7/32"
  
    - path: /interface[name=ethernet-1/1]
      value:
       description: "spine ~ l1"
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
       mtu: 1614
       subinterface:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
        ip-mtu: 1600
        index: 0
        description: "spine ~ l1"
  
    - path: /interface[name=ethernet-1/1]/subinterface[index=0]
      value:
       description: "spine ~ l1"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.1.0.2/30"
          primary: [null]
  
    - path: /interface[name=ethernet-1/2]
      value:
       description: "spine ~ l2"
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
       mtu: 1614
       subinterface:
     # min 1500; max 9412 for 7220, 9500 for 7250 platforms
        ip-mtu: 1600
        index: 0
        description: "spine ~ l2"
  
    - path: /interface[name=ethernet-1/2]/subinterface[index=0]
      value:
       description: "spine ~ l2"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "10.1.0.6/30"
          primary: [null]
  
  
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: system0.0
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: ethernet-1/1.0
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: ethernet-1/2.0
  
  
  
    # TODO: vdata.rd, vdata.import/export, vdata.af

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/linux-clab.yml for h1, h2, h3, h4
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/initial-clab.yml for l2

TASK [Define script filename and determine whether to execute in netns] ********
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]

TASK [Create a temporary file for the rendered script] *************************
changed: [h2 -> localhost]
changed: [h1 -> localhost]
changed: [h3 -> localhost]
changed: [h4 -> localhost]

TASK [Create container setup script from /home/pipi/net101/tools/netsim/ansible/templates/initial/linux-clab.j2] ***
changed: [h3 -> localhost]
changed: [h1 -> localhost]
changed: [h2 -> localhost]
changed: [h4 -> localhost]

TASK [Copy script into running container at /tmp/config-h1_initial.sh] *********
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]

TASK [Execute /tmp/config-h1_initial.sh to deploy initial config based on /home/pipi/net101/tools/netsim/ansible/templates/initial/linux-clab.j2] ***
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]

TASK [Container configuration for initial based on /home/pipi/net101/tools/netsim/ansible/templates/initial/linux-clab.j2 executed in netns] ***
changed: [h1 -> localhost]
changed: [h4 -> localhost]
changed: [h3 -> localhost]
changed: [h2 -> localhost]

TASK [Remove temporary file /tmp/h1_initial-pdb7pzpn.sh] ***********************
changed: [h4 -> localhost]
changed: [h3 -> localhost]
changed: [h1 -> localhost]
changed: [h2 -> localhost]

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL initial node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/initial/srlinux.j2)] ***
changed: [spine]
changed: [l1]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [Attempt to load VRF kernel module] ***************************************
changed: [l2 -> localhost]

TASK [Disable FRR management VRF when modprobe fails] **************************
skipping: [l2]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for l2

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
changed: [l2]

TASK [run vtysh to import initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
skipping: [l2]

PLAY [Deploy module-specific configurations] ***********************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Deploy individual configuration modules] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine => (item=vlan)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine => (item=routing)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine => (item=ospf)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine => (item=bgp)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine => (item=vrf)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine => (item=vxlan)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for h1, h2, h3, h4, l1, l2, spine => (item=evpn)

TASK [Figure out whether to deploy the module vlan on current device] **********
ok: [h1]
ok: [h2]
ok: [h3]
ok: [l1]
ok: [h4]
ok: [l2]
ok: [spine]

TASK [Find configuration template for vlan] ************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for vlan] ********************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l2] => 
  msg: |-
    vlan configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
    if [ ! -e /sys/devices/virtual/net/vlan1000 ]; then
      ip link add vlan1000 type bridge
      ip link set dev vlan1000 address 52:dc:ca:fd:06:00
  
      ip addr flush dev vlan1000
    fi
    if [ ! -e /sys/devices/virtual/net/vlan1001 ]; then
      ip link add vlan1001 type bridge
      ip link set dev vlan1001 address 52:dc:ca:fd:06:01
  
      ip addr flush dev vlan1001
    fi
  
    ip link set dev eth2 master vlan1000
    ip link set dev eth3 master vlan1001
  
    ip link set dev vlan1000 up
    ip link set dev vlan1001 up
ok: [l1] => 
  msg: |-
    vlan configuration for l1
    =========================================
  
    updates:
    - path: /interface[name=ethernet-1/2]
      value:
       subinterface:
       - index: 1000
         type: bridged
         description: "Access VLAN red l1 ~ h1"
  
  
    - path: /network-instance[name=vlan1000]
      value:
       type: mac-vrf
       description: "Access VLAN red l1 ~ h1"
       interface:
       - name: ethernet-1/2.1000
  
  
    - path: /interface[name=ethernet-1/3]
      value:
       subinterface:
       - index: 1001
         type: bridged
         description: "Access VLAN blue l1 ~ h3"
  
  
    - path: /network-instance[name=vlan1001]
      value:
       type: mac-vrf
       description: "Access VLAN blue l1 ~ h3"
       interface:
       - name: ethernet-1/3.1001
  
  
    - path: /interface[name=irb0]
      value:
       subinterface:
       - index: 1000
  
  
  
  
    - path: /interface[name=irb0]
      value:
       subinterface:
       - index: 1001
ok: [spine] => 
  msg: |-
    vlan configuration for spine
    =========================================
  
    updates:
    - path: /interface[name=irb0]
      value:
       subinterface:
       - index: 1000
  
    - path: /interface[name=irb0]/subinterface[index=1000]
      value:
       description: "VLAN red (1000) ~ h1,l1,h2,l2"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "172.16.0.7/24"
          primary: [null]
  
  
    - path: /network-instance[name=vlan1000]
      value:
       type: mac-vrf
       description: "VLAN red (1000) ~ h1,l1,h2,l2"
       interface:
       - name: irb0.1000
  
    - path: /network-instance[name=customer]
      value:
       type: ip-vrf
       interface:
       - name: irb0.1000
  
    - path: /interface[name=irb0]
      value:
       subinterface:
       - index: 1001
  
    - path: /interface[name=irb0]/subinterface[index=1001]
      value:
       description: "VLAN blue (1001) ~ h3,l1,h4,l2"
       ipv4:
        admin-state: enable
        address:
        - ip-prefix: "172.16.1.7/24"
          primary: [null]
  
  
    - path: /network-instance[name=vlan1001]
      value:
       type: mac-vrf
       description: "VLAN blue (1001) ~ h3,l1,h4,l2"
       interface:
       - name: irb0.1001
  
    - path: /network-instance[name=customer]
      value:
       type: ip-vrf
       interface:
       - name: irb0.1001

TASK [Deploy vlan configuration] ***********************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL vlan node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/vlan/srlinux.j2)] ***
changed: [l1]
changed: [spine]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy vlan config from /home/pipi/net101/tools/netsim/ansible/templates/vlan/frr.j2] ***
changed: [l2]

TASK [run vtysh to import vlan config from /home/pipi/net101/tools/netsim/ansible/templates/vlan/frr.j2] ***
skipping: [l2]

TASK [Figure out whether to deploy the module routing on current device] *******
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for routing] *********************************
ok: [h1]
skipping: [l1]
ok: [h2]
ok: [h3]
skipping: [l2]
skipping: [spine]
ok: [h4]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for routing] *****************
skipping: [l1]
ok: [h1]
skipping: [l2]
ok: [h2]
ok: [h3]
skipping: [spine]
ok: [h4]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [l1]
skipping: [l2]
ok: [h1] => 
  msg: |-
    routing configuration for h1
    =========================================
    #!/bin/bash
    #
    # Add static routes (usually IPv4 routes pointing to the first usable gateway)
    #
    #
    echo Removing existing IPv4 routes
    while ip route del 172.16.0.0/16 2>/dev/null; do
      : ; done
    while ip route del 10.0.0.0/24 2>/dev/null; do
      : ; done
    while ip route del 10.1.0.0/16 2>/dev/null; do
      : ; done
    while ip route del 10.2.0.0/24 2>/dev/null; do
      : ; done
    #
    #
    #
    echo Adding direct static routes
    ip route add 172.16.0.0/16 via 172.16.0.7 dev eth1 protocol static
    ip route add 10.0.0.0/24 via 172.16.0.7 dev eth1 protocol static
    ip route add 10.1.0.0/16 via 172.16.0.7 dev eth1 protocol static
    ip route add 10.2.0.0/24 via 172.16.0.7 dev eth1 protocol static
    #
    # Print the final routing table
    ip route
ok: [h2] => 
  msg: |-
    routing configuration for h2
    =========================================
    #!/bin/bash
    #
    # Add static routes (usually IPv4 routes pointing to the first usable gateway)
    #
    #
    echo Removing existing IPv4 routes
    while ip route del 172.16.0.0/16 2>/dev/null; do
      : ; done
    while ip route del 10.0.0.0/24 2>/dev/null; do
      : ; done
    while ip route del 10.1.0.0/16 2>/dev/null; do
      : ; done
    while ip route del 10.2.0.0/24 2>/dev/null; do
      : ; done
    #
    #
    #
    echo Adding direct static routes
    ip route add 172.16.0.0/16 via 172.16.0.7 dev eth1 protocol static
    ip route add 10.0.0.0/24 via 172.16.0.7 dev eth1 protocol static
    ip route add 10.1.0.0/16 via 172.16.0.7 dev eth1 protocol static
    ip route add 10.2.0.0/24 via 172.16.0.7 dev eth1 protocol static
    #
    # Print the final routing table
    ip route
skipping: [spine]
ok: [h4] => 
  msg: |-
    routing configuration for h4
    =========================================
    #!/bin/bash
    #
    # Add static routes (usually IPv4 routes pointing to the first usable gateway)
    #
    #
    echo Removing existing IPv4 routes
    while ip route del 172.16.0.0/16 2>/dev/null; do
      : ; done
    while ip route del 10.0.0.0/24 2>/dev/null; do
      : ; done
    while ip route del 10.1.0.0/16 2>/dev/null; do
      : ; done
    while ip route del 10.2.0.0/24 2>/dev/null; do
      : ; done
    #
    #
    #
    echo Adding direct static routes
    ip route add 172.16.0.0/16 via 172.16.1.7 dev eth1 protocol static
    ip route add 10.0.0.0/24 via 172.16.1.7 dev eth1 protocol static
    ip route add 10.1.0.0/16 via 172.16.1.7 dev eth1 protocol static
    ip route add 10.2.0.0/24 via 172.16.1.7 dev eth1 protocol static
    #
    # Print the final routing table
    ip route
ok: [h3] => 
  msg: |-
    routing configuration for h3
    =========================================
    #!/bin/bash
    #
    # Add static routes (usually IPv4 routes pointing to the first usable gateway)
    #
    #
    echo Removing existing IPv4 routes
    while ip route del 172.16.0.0/16 2>/dev/null; do
      : ; done
    while ip route del 10.0.0.0/24 2>/dev/null; do
      : ; done
    while ip route del 10.1.0.0/16 2>/dev/null; do
      : ; done
    while ip route del 10.2.0.0/24 2>/dev/null; do
      : ; done
    #
    #
    #
    echo Adding direct static routes
    ip route add 172.16.0.0/16 via 172.16.1.7 dev eth1 protocol static
    ip route add 10.0.0.0/24 via 172.16.1.7 dev eth1 protocol static
    ip route add 10.1.0.0/16 via 172.16.1.7 dev eth1 protocol static
    ip route add 10.2.0.0/24 via 172.16.1.7 dev eth1 protocol static
    #
    # Print the final routing table
    ip route

TASK [Deploy routing configuration] ********************************************
skipping: [l1]
skipping: [l2]
skipping: [spine]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/linux-clab.yml for h1, h2, h3, h4

TASK [Define script filename and determine whether to execute in netns] ********
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]

TASK [Create a temporary file for the rendered script] *************************
changed: [h1 -> localhost]
changed: [h2 -> localhost]
changed: [h3 -> localhost]
changed: [h4 -> localhost]

TASK [Create container setup script from /home/pipi/net101/tools/netsim/ansible/templates/routing/linux-clab.j2] ***
changed: [h2 -> localhost]
changed: [h1 -> localhost]
changed: [h3 -> localhost]
changed: [h4 -> localhost]

TASK [Copy script into running container at /tmp/config-h1_routing.sh] *********
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]

TASK [Execute /tmp/config-h1_routing.sh to deploy routing config based on /home/pipi/net101/tools/netsim/ansible/templates/routing/linux-clab.j2] ***
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]

TASK [Container configuration for routing based on /home/pipi/net101/tools/netsim/ansible/templates/routing/linux-clab.j2 executed in netns] ***
changed: [h2 -> localhost]
changed: [h1 -> localhost]
changed: [h3 -> localhost]
changed: [h4 -> localhost]

TASK [Remove temporary file /tmp/h1_routing-h7sib9ee.sh] ***********************
changed: [h1 -> localhost]
changed: [h2 -> localhost]
changed: [h3 -> localhost]
changed: [h4 -> localhost]

TASK [Figure out whether to deploy the module ospf on current device] **********
ok: [h1]
ok: [h2]
ok: [h3]
ok: [l1]
ok: [h4]
ok: [l2]
ok: [spine]

TASK [Find configuration template for ospf] ************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for ospf] ********************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1] => 
  msg: |-
    ospf configuration for l1
    =========================================
    updates:
  
  
    - path: /network-instance[name=default]
      value:
        router-id: 10.0.0.5
        protocols:
          ospf:
            instance:
            - name: "0"
              version: ospf-v2
              admin-state: enable
              max-ecmp-paths: 64
              area:
              - area-id: 0.0.0.0
                interface:
                - interface-name: system0.0
                  passive: True
              - area-id: 0.0.0.0
                interface:
                - interface-name: ethernet-1/1.0
                  interface-type: "point-to-point"
                  failure-detection:
                    enable-bfd: False
           # OSPF not configured on external interface ethernet-1/2
           # OSPF not configured on external interface ethernet-1/3
ok: [spine] => 
  msg: |-
    ospf configuration for spine
    =========================================
    updates:
  
  
    - path: /network-instance[name=default]
      value:
        router-id: 10.0.0.7
        protocols:
          ospf:
            instance:
            - name: "0"
              version: ospf-v2
              admin-state: enable
              max-ecmp-paths: 64
              area:
              - area-id: 0.0.0.0
                interface:
                - interface-name: system0.0
                  passive: True
              - area-id: 0.0.0.0
                interface:
                - interface-name: ethernet-1/1.0
                  interface-type: "point-to-point"
                  failure-detection:
                    enable-bfd: False
              - area-id: 0.0.0.0
                interface:
                - interface-name: ethernet-1/2.0
                  interface-type: "point-to-point"
                  failure-detection:
                    enable-bfd: False
           # OSPF not configured on external interface irb0.1000
           # OSPF not configured on external interface irb0.1001
ok: [l2] => 
  msg: |-
    ospf configuration for l2
    =========================================
    !
    ! OSPFv2 FRR configuration
    !
    router ospf
     ospf router-id 10.0.0.6
     timers throttle spf 10 50 500
     timers throttle lsa all 100
     timers lsa min-arrival 100
  
  
    exit
    !
    interface lo
    !
     ip ospf area 0.0.0.0
    !
    interface eth1
    ! l2 -> spine
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
  
    !
    do write

TASK [Deploy ospf configuration] ***********************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL ospf node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/ospf/srlinux.j2)] ***
changed: [spine]
changed: [l1]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy ospf config from /home/pipi/net101/tools/netsim/ansible/templates/ospf/frr.j2] ***
skipping: [l2]

TASK [run vtysh to import ospf config from /home/pipi/net101/tools/netsim/ansible/templates/ospf/frr.j2] ***
changed: [l2]

TASK [Figure out whether to deploy the module bgp on current device] ***********
ok: [h1]
ok: [h2]
ok: [h3]
ok: [l1]
ok: [h4]
ok: [l2]
ok: [spine]

TASK [Find configuration template for bgp] *************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for bgp] *********************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l2] => 
  msg: |-
    bgp configuration for l2
    =========================================
    !
    router bgp 65000
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.6
    !
      neighbor 10.0.0.7 remote-as 65000
      neighbor 10.0.0.7 description spine
      neighbor 10.0.0.7 update-source lo
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.6/32
    !
    !
    !
      neighbor 10.0.0.7 activate
      neighbor 10.0.0.7 next-hop-self
      no neighbor 10.0.0.7 send-community all
      neighbor 10.0.0.7 send-community standard
      neighbor 10.0.0.7 send-community large
      neighbor 10.0.0.7 send-community extended
    !
    !
    !
    do write
ok: [l1] => 
  msg: |-
    bgp configuration for l1
    =========================================
    updates:
  
    - path: /routing-policy/policy[name=accept_all]
      value:
        default-action:
          policy-result: accept
  
    - path: /routing-policy/community-set[name=ibgp-mark]
      value:
        member: [ "65536:0:65536" ]
  
    - path: /routing-policy/policy[name=ibgp-mark]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: mark-ibgp-routes
          action:
            bgp:
              communities:
                add: ibgp-mark
            policy-result: accept
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix: [] # Make sure it exists
  
    - path: /routing-policy/policy[name=default_bgp_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
           prefix:
            prefix-set: default_bgp_advertise
          action:
            policy-result: next-policy
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: next-policy
            bgp:
              communities:
                remove:
                  ibgp-mark
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        admin-state: enable
        autonomous-system: 65000
        router-id: 10.0.0.5
        ebgp-default-policy:
          export-reject-all: False
          import-reject-all: False
  
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix:
        - ip-prefix: 10.0.0.5/32
          mask-length-range: exact
  
  
  
  
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ibgp-ipv4]
      value:
        admin-state: enable
    # neighbor: {'rr': True, 'name': 'spine', 'as': 65000, 'type': 'ibgp', 'ipv4': '10.0.0.7', '_source_intf': {'type': 'loopback', 'neighbors': [], 'virtual_interface': True, 'ifindex': 0, 'ifname': 'lo0.0', 'ipv4': '10.0.0.5/32'}, 'activate': {'ipv4': True}, 'evpn': True}
    # ipv4: True
    # ipv6: True
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
          send-community-type: ['standard', 'large', 'extended']
  
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          send-community-type: ['standard', 'large', 'extended']
  
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: evpn
          admin-state: enable
          send-community-type: ['standard', 'large', 'extended']
  
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        peer-as: 65000
        transport:
          local-address: 10.0.0.5
        next-hop-self: True
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.0.0.7"
          description: spine
          peer-group: ibgp-ipv4
      # neighbor: {'rr': True, 'name': 'spine', 'as': 65000, 'type': 'ibgp', 'ipv4': '10.0.0.7', '_source_intf': {'type': 'loopback', 'neighbors': [], 'virtual_interface': True, 'ifindex': 0, 'ifname': 'lo0.0', 'ipv4': '10.0.0.5/32'}, 'activate': {'ipv4': True}, 'evpn': True}
      # ipv4: True
      # ipv6: False
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: enable
            send-community-type: ['standard', 'large', 'extended']
  
          - afi-safi-name: ipv6-unicast
            admin-state: disable
          - afi-safi-name: evpn
            admin-state: enable
            send-community-type: ['standard', 'large', 'extended']
ok: [spine] => 
  msg: |-
    bgp configuration for spine
    =========================================
    updates:
  
    - path: /routing-policy/policy[name=accept_all]
      value:
        default-action:
          policy-result: accept
  
    - path: /routing-policy/community-set[name=ibgp-mark]
      value:
        member: [ "65536:0:65536" ]
  
    - path: /routing-policy/policy[name=ibgp-mark]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: mark-ibgp-routes
          action:
            bgp:
              communities:
                add: ibgp-mark
            policy-result: accept
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix: [] # Make sure it exists
  
    - path: /routing-policy/policy[name=default_bgp_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
           prefix:
            prefix-set: default_bgp_advertise
          action:
            policy-result: next-policy
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: next-policy
            bgp:
              communities:
                remove:
                  ibgp-mark
  
  
    - path: /routing-policy/policy[name=default_ibgp-nhs_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
           prefix:
            prefix-set: default_bgp_advertise
          action:
            policy-result: next-policy
        - name: rr-next-hop-unchanged
          match:
            protocol: bgp
            bgp:
              community-set: ibgp-mark
          action:
            policy-result: next-policy
            bgp:
              communities:
                remove:
                  ibgp-mark
        - name: ebgp-next-hop-self
          match:
            protocol: bgp
          action:
            policy-result: next-policy
            bgp:
              next-hop:
                set: self
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        admin-state: enable
        autonomous-system: 65000
        router-id: 10.0.0.7
        ebgp-default-policy:
          export-reject-all: False
          import-reject-all: False
  
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix:
        - ip-prefix: 10.0.0.7/32
          mask-length-range: exact
  
  
  
  
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ibgp-ipv4]
      value:
        admin-state: enable
    # neighbor: {'name': 'l1', 'as': 65000, 'type': 'ibgp', 'ipv4': '10.0.0.5', '_source_intf': {'type': 'loopback', 'neighbors': [], 'virtual_interface': True, 'ifindex': 0, 'ifname': 'lo0.0', 'ipv4': '10.0.0.7/32'}, 'activate': {'ipv4': True}, 'evpn': True}
    # ipv4: True
    # ipv6: True
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
          send-community-type: ['standard', 'large', 'extended']
  
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          send-community-type: ['standard', 'large', 'extended']
  
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
        - afi-safi-name: evpn
          admin-state: enable
          send-community-type: ['standard', 'large', 'extended']
  
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        peer-as: 65000
        transport:
          local-address: 10.0.0.7
        route-reflector:
          cluster-id: 10.0.0.7
          client: True
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.0.0.5"
          description: l1
          peer-group: ibgp-ipv4
      # neighbor: {'name': 'l1', 'as': 65000, 'type': 'ibgp', 'ipv4': '10.0.0.5', '_source_intf': {'type': 'loopback', 'neighbors': [], 'virtual_interface': True, 'ifindex': 0, 'ifname': 'lo0.0', 'ipv4': '10.0.0.7/32'}, 'activate': {'ipv4': True}, 'evpn': True}
      # ipv4: True
      # ipv6: False
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: enable
            send-community-type: ['standard', 'large', 'extended']
  
          - afi-safi-name: ipv6-unicast
            admin-state: disable
          - afi-safi-name: evpn
            admin-state: enable
            send-community-type: ['standard', 'large', 'extended']
  
  
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ibgp-ipv4]
      value:
        admin-state: enable
    # neighbor: {'name': 'l2', 'as': 65000, 'type': 'ibgp', 'ipv4': '10.0.0.6', '_source_intf': {'type': 'loopback', 'neighbors': [], 'virtual_interface': True, 'ifindex': 0, 'ifname': 'lo0.0', 'ipv4': '10.0.0.7/32'}, 'activate': {'ipv4': True}, 'evpn': True}
    # ipv4: True
    # ipv6: True
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
          send-community-type: ['standard', 'large', 'extended']
  
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: disable
          send-community-type: ['standard', 'large', 'extended']
  
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
        - afi-safi-name: evpn
          admin-state: enable
          send-community-type: ['standard', 'large', 'extended']
  
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        peer-as: 65000
        transport:
          local-address: 10.0.0.7
        route-reflector:
          cluster-id: 10.0.0.7
          client: True
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "10.0.0.6"
          description: l2
          peer-group: ibgp-ipv4
      # neighbor: {'name': 'l2', 'as': 65000, 'type': 'ibgp', 'ipv4': '10.0.0.6', '_source_intf': {'type': 'loopback', 'neighbors': [], 'virtual_interface': True, 'ifindex': 0, 'ifname': 'lo0.0', 'ipv4': '10.0.0.7/32'}, 'activate': {'ipv4': True}, 'evpn': True}
      # ipv4: True
      # ipv6: False
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: enable
            send-community-type: ['standard', 'large', 'extended']
  
          - afi-safi-name: ipv6-unicast
            admin-state: disable
          - afi-safi-name: evpn
            admin-state: enable
            send-community-type: ['standard', 'large', 'extended']

TASK [Deploy bgp configuration] ************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL bgp node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/bgp/srlinux.j2)] ***
changed: [l1]
changed: [spine]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
skipping: [l2]

TASK [run vtysh to import bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
changed: [l2]

TASK [Figure out whether to deploy the module vrf on current device] ***********
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for vrf] *************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for vrf] *********************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l2] => 
  msg: |-
    vrf configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
  
    # Create VRF tables
    if [ ! -e /sys/devices/virtual/net/customer ]; then
    ip link add customer type vrf table 100
    fi
    ip link set customer up
  
    # Move interfaces and loopbacks to vrfs
    sysctl -qw net.ipv6.conf.vlan1000.keep_addr_on_down=1
    ip link set vlan1000 master customer
    sysctl -qw net.ipv6.conf.vlan1001.keep_addr_on_down=1
    ip link set vlan1001 master customer
  
    cat >/tmp/vrf_config <<CONFIG
    vrf customer
     exit-vrf
    !
    router bgp 65000
    !
    !
    router bgp 65000 vrf customer
     no bgp ebgp-requires-policy
     no bgp default ipv4-unicast
     bgp router-id 10.0.0.6
    !
    !
    do write
    !
    CONFIG
    vtysh -f /tmp/vrf_config
    exit $?
ok: [l1] => 
  msg: |-
    vrf configuration for l1
    =========================================
  
    updates:
  
    - path: /network-instance[name=customer]
      value:
       type: ip-vrf
  
  
    - path: /routing-policy/community-set[name=C65000_1]
      value:
       member:
       - "target:65000:1" # Single member, else matching is AND
  
    - path: /routing-policy/community-set[name=customer_export]
      value:
       member:
       - "target:65000:1"
  
  
    - path: /network-instance[name=customer]/protocols/bgp-vpn
      value:
       bgp-instance:
       - id: 1
         route-distinguisher:
          rd: "65000:1"
  
    - path: /network-instance[name=customer]/inter-instance-policies
      value:
       apply-policy:
        export-policy: "customer_vpn_export"
        import-policy: "customer_vpn_import"
  
    - path: /routing-policy/policy[name=customer_vpn_export]
      value:
       default-action:
        policy-result: "accept"
        bgp:
         communities:
          add: "customer_export"
  
    - path: /routing-policy/policy[name=customer_vpn_import]
      value:
       default-action:
        policy-result: "reject"
       statement:
       - name: 11
         match:
          bgp:
           community-set: "C65000_1"
         action:
          policy-result: "accept"
ok: [spine] => 
  msg: |-
    vrf configuration for spine
    =========================================
  
    updates:
  
    - path: /network-instance[name=customer]
      value:
       type: ip-vrf
  
  
    - path: /routing-policy/community-set[name=C65000_1]
      value:
       member:
       - "target:65000:1" # Single member, else matching is AND
  
    - path: /routing-policy/community-set[name=customer_export]
      value:
       member:
       - "target:65000:1"
  
  
    - path: /routing-policy/policy[name=customer_bgp_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: next-policy
            bgp:
              communities:
                remove:
                  ibgp-mark
        - name: bgp_evpn
          match:
            protocol: bgp-evpn
          action:
            policy-result: next-policy
        - name: export_local
          match:
            protocol: local
          action:
            policy-result: next-policy
  
  
    - path: /network-instance[name=customer]/protocols/bgp
      value:
        admin-state: enable
        autonomous-system: 65000
        router-id: 10.0.0.7
        ebgp-default-policy:
          export-reject-all: False
          import-reject-all: False
  
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: enable
  
  
  
  
  
  
  
  
    - path: /network-instance[name=customer]/protocols/bgp-vpn
      value:
       bgp-instance:
       - id: 1
         route-distinguisher:
          rd: "65000:1"
  
    - path: /network-instance[name=customer]/inter-instance-policies
      value:
       apply-policy:
        export-policy: "customer_vpn_export"
        import-policy: "customer_vpn_import"
  
    - path: /routing-policy/policy[name=customer_vpn_export]
      value:
       default-action:
        policy-result: "accept"
        bgp:
         communities:
          add: "customer_export"
  
    - path: /routing-policy/policy[name=customer_vpn_import]
      value:
       default-action:
        policy-result: "reject"
       statement:
       - name: 11
         match:
          bgp:
           community-set: "C65000_1"
         action:
          policy-result: "accept"

TASK [Deploy vrf configuration] ************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL vrf node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/vrf/srlinux.j2)] ***
changed: [l1]
changed: [spine]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy vrf config from /home/pipi/net101/tools/netsim/ansible/templates/vrf/frr.j2] ***
changed: [l2]

TASK [run vtysh to import vrf config from /home/pipi/net101/tools/netsim/ansible/templates/vrf/frr.j2] ***
skipping: [l2]

TASK [Figure out whether to deploy the module vxlan on current device] *********
ok: [h1]
ok: [h2]
ok: [h3]
ok: [l1]
ok: [h4]
ok: [l2]
ok: [spine]

TASK [Find configuration template for vxlan] ***********************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for vxlan] *******************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [spine]
ok: [l2]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1] => 
  msg: |-
    vxlan configuration for l1
    =========================================
  
    updates:
    - path: /tunnel-interface[name=vxlan0]/vxlan-interface[index=1000]
      value:
       type: bridged
       ingress:
        vni: 1000
       egress:
        source-ip: use-system-ipv4-address
  
    - path: /network-instance[name=vlan1000]
      value:
       type: mac-vrf
       vxlan-interface:
       - name: vxlan0.1000
       protocols:
        bgp-vpn:
         bgp-instance:
         - id: 1
           # route-distinguisher:
           # rd: "10.0.0.5:1000"
           _annotate: "RD left as <auto> for EVPN services and ECMP to work as expected, not '10.0.0.5:1000'"
           route-target:
            _annotate: "For compatibility with frr, override auto-derived RT based on EVI 1000 with VNI 1000"
            import-rt: "target:65000:1000"
            export-rt: "target:65000:1000"
        bgp-evpn:
         bgp-instance:
         - id: 1
           evi: 1000
           ecmp: 8
           vxlan-interface: vxlan0.1000
  
    - path: /tunnel-interface[name=vxlan0]/vxlan-interface[index=1001]
      value:
       type: bridged
       ingress:
        vni: 1001
       egress:
        source-ip: use-system-ipv4-address
  
    - path: /network-instance[name=vlan1001]
      value:
       type: mac-vrf
       vxlan-interface:
       - name: vxlan0.1001
       protocols:
        bgp-vpn:
         bgp-instance:
         - id: 1
           # route-distinguisher:
           # rd: "10.0.0.5:1001"
           _annotate: "RD left as <auto> for EVPN services and ECMP to work as expected, not '10.0.0.5:1001'"
           route-target:
            _annotate: "For compatibility with frr, override auto-derived RT based on EVI 1001 with VNI 1001"
            import-rt: "target:65000:1001"
            export-rt: "target:65000:1001"
        bgp-evpn:
         bgp-instance:
         - id: 1
           evi: 1001
           ecmp: 8
           vxlan-interface: vxlan0.1001
ok: [l2] => 
  msg: |-
    vxlan configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
  
  
  
    # Create L3 VNIs with bridges and add to correct vrf table
  
    # Create VXLAN L2 interface per vni
    ip link add vxlan1000 type vxlan \
      id 1000 \
      dstport 4789 \
      local 10.0.0.6 nolearning
    #
    # Add it to the VLAN bridge (create if needed for l3 vnis); disable STP
    if [ ! -e /sys/devices/virtual/net/vlan1000 ]; then
    ip link add vlan1000 type bridge
    ip link set up dev vlan1000
    fi
    ip link set dev vxlan1000 master vlan1000
    ip link set vlan1000 type bridge stp_state 0
  
    # Do not generate ipv6 link-local address for VXLAN devices
    ip link set mtu 1500 addrgenmode none dev vxlan1000
    # Disable dynamic MAC learning for evpn, see https://docs.frrouting.org/en/latest/evpn.html
    bridge link set dev vxlan1000 learning off
    ip link set up dev vxlan1000
  
    # Create VXLAN L2 interface per vni
    ip link add vxlan1001 type vxlan \
      id 1001 \
      dstport 4789 \
      local 10.0.0.6 nolearning
    #
    # Add it to the VLAN bridge (create if needed for l3 vnis); disable STP
    if [ ! -e /sys/devices/virtual/net/vlan1001 ]; then
    ip link add vlan1001 type bridge
    ip link set up dev vlan1001
    fi
    ip link set dev vxlan1001 master vlan1001
    ip link set vlan1001 type bridge stp_state 0
  
    # Do not generate ipv6 link-local address for VXLAN devices
    ip link set mtu 1500 addrgenmode none dev vxlan1001
    # Disable dynamic MAC learning for evpn, see https://docs.frrouting.org/en/latest/evpn.html
    bridge link set dev vxlan1001 learning off
    ip link set up dev vxlan1001
  
  
    exit $?
ok: [spine] => 
  msg: |-
    vxlan configuration for spine
    =========================================
  
    updates:
    - path: /tunnel-interface[name=vxlan0]/vxlan-interface[index=1000]
      value:
       type: bridged
       ingress:
        vni: 1000
       egress:
        source-ip: use-system-ipv4-address
  
    - path: /network-instance[name=vlan1000]
      value:
       type: mac-vrf
       vxlan-interface:
       - name: vxlan0.1000
       protocols:
        bgp-vpn:
         bgp-instance:
         - id: 1
           # route-distinguisher:
           # rd: "10.0.0.7:1000"
           _annotate: "RD left as <auto> for EVPN services and ECMP to work as expected, not '10.0.0.7:1000'"
           route-target:
            _annotate: "For compatibility with frr, override auto-derived RT based on EVI 1000 with VNI 1000"
            import-rt: "target:65000:1000"
            export-rt: "target:65000:1000"
        bgp-evpn:
         bgp-instance:
         - id: 1
           evi: 1000
           ecmp: 8
           vxlan-interface: vxlan0.1000
  
    - path: /tunnel-interface[name=vxlan0]/vxlan-interface[index=1001]
      value:
       type: bridged
       ingress:
        vni: 1001
       egress:
        source-ip: use-system-ipv4-address
  
    - path: /network-instance[name=vlan1001]
      value:
       type: mac-vrf
       vxlan-interface:
       - name: vxlan0.1001
       protocols:
        bgp-vpn:
         bgp-instance:
         - id: 1
           # route-distinguisher:
           # rd: "10.0.0.7:1001"
           _annotate: "RD left as <auto> for EVPN services and ECMP to work as expected, not '10.0.0.7:1001'"
           route-target:
            _annotate: "For compatibility with frr, override auto-derived RT based on EVI 1001 with VNI 1001"
            import-rt: "target:65000:1001"
            export-rt: "target:65000:1001"
        bgp-evpn:
         bgp-instance:
         - id: 1
           evi: 1001
           ecmp: 8
           vxlan-interface: vxlan0.1001

TASK [Deploy vxlan configuration] **********************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL vxlan node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/vxlan/srlinux.j2)] ***
changed: [spine]
changed: [l1]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy vxlan config from /home/pipi/net101/tools/netsim/ansible/templates/vxlan/frr.j2] ***
changed: [l2]

TASK [run vtysh to import vxlan config from /home/pipi/net101/tools/netsim/ansible/templates/vxlan/frr.j2] ***
skipping: [l2]

TASK [Figure out whether to deploy the module evpn on current device] **********
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Find configuration template for evpn] ************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [fail] ********************************************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
skipping: [l1]
skipping: [l2]
skipping: [spine]

TASK [Find configuration deployment deploy_script for evpn] ********************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1]
ok: [l2]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
ok: [l1] => 
  msg: |-
    evpn configuration for l1
    =========================================
  
  
    updates:
    - path: /network-instance[name=default]/protocols/bgp
      value:
        group:
        - group-name: ibgp-ipv4 # Could create a dedicated group for EVPN only?
          afi-safi:
          - afi-safi-name: evpn
            admin-state: enable
        route-advertisement:
          rapid-withdrawal: True
        afi-safi:
        - afi-safi-name: evpn
          evpn:
            rapid-update: True
ok: [l2] => 
  msg: |-
    evpn configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e
    cat >/tmp/evpn_config <<CONFIG
    router bgp 65000
     address-family l2vpn evpn
      advertise-all-vni
      advertise-svi-ip
      advertise ipv4 unicast
  
    ! Configure explicit Route Targets and RD per L2 VNI; auto-derived differs
      vni 1000
       rd 10.0.0.6:1000
       route-target import 65000:1000
       route-target export 65000:1000
      exit-vni
      vni 1001
       rd 10.0.0.6:1001
       route-target import 65000:1001
       route-target export 65000:1001
      exit-vni
  
      neighbor 10.0.0.7 activate
    #  neighbor 10.0.0.7 soft-reconfiguration inbound
  
     exit-address-family
    !
  
    exit
  
    ! L3 VRF EVPN handling
    !
    do write
    CONFIG
    vtysh -f /tmp/evpn_config
    vtysh -c 'clear bgp *'
ok: [spine] => 
  msg: |-
    evpn configuration for spine
    =========================================
  
  
    updates:
    - path: /network-instance[name=default]/protocols/bgp
      value:
        group:
        - group-name: ibgp-ipv4 # Could create a dedicated group for EVPN only?
          afi-safi:
          - afi-safi-name: evpn
            admin-state: enable
        route-advertisement:
          rapid-withdrawal: True
        afi-safi:
        - afi-safi-name: evpn
          evpn:
            rapid-update: True
  
    - path: /interface[name=irb0]/subinterface[index=1000]
      value:
       ipv4:
         arp:
           learn-unsolicited: True
           evpn:
            advertise: # Type of ARP/ND entries to be advertised
            - route-type: dynamic
              _annotate: "Advertise dynamically learned IPs"
            - route-type: static
              _annotate: "Advertise local irb interface IPs"
  
  
    - path: /interface[name=irb0]/subinterface[index=1001]
      value:
       ipv4:
         arp:
           learn-unsolicited: True
           evpn:
            advertise: # Type of ARP/ND entries to be advertised
            - route-type: dynamic
              _annotate: "Advertise dynamically learned IPs"
            - route-type: static
              _annotate: "Advertise local irb interface IPs"

TASK [Deploy evpn configuration] ***********************************************
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [l1]
ok: [spine]

TASK [Update SRL evpn node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/evpn/srlinux.j2)] ***
changed: [l1]
changed: [spine]

TASK [debug] *******************************************************************
skipping: [l1]
skipping: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy evpn config from /home/pipi/net101/tools/netsim/ansible/templates/evpn/frr.j2] ***
changed: [l2]

TASK [run vtysh to import evpn config from /home/pipi/net101/tools/netsim/ansible/templates/evpn/frr.j2] ***
skipping: [l2]

PLAY [Deploy custom deployment templates] **************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
h1                         : ok=41   changed=8    unreachable=0    failed=0    skipped=40   rescued=0    ignored=0   
h2                         : ok=41   changed=8    unreachable=0    failed=0    skipped=40   rescued=0    ignored=0   
h3                         : ok=41   changed=8    unreachable=0    failed=0    skipped=40   rescued=0    ignored=0   
h4                         : ok=41   changed=8    unreachable=0    failed=0    skipped=40   rescued=0    ignored=0   
l1                         : ok=65   changed=7    unreachable=0    failed=0    skipped=23   rescued=0    ignored=0   
l2                         : ok=74   changed=15   unreachable=0    failed=0    skipped=24   rescued=0    ignored=0   
spine                      : ok=65   changed=7    unreachable=0    failed=0    skipped=23   rescued=0    ignored=0   



The devices under test are a layer-2 leaf and a spine performing centralized
routing.

All hosts should be able to ping each other and all switch loopback IPs

Please note it might take a while for the lab to work due to STP learning
phase.

