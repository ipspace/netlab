[WARNING]: Could not match supplied host pattern, ignoring: unprovisioned

PLAY [Deploy initial device configuration] *************************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [dut]
ok: [r1]
ok: [r3]
ok: [r2]
ok: [r4]

TASK [Find device readiness script] ********************************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Wait for device to become ready] *****************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4

TASK [Figure out whether to deploy the module initial on current device] *******
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Find configuration template for initial] *********************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [dut] => 
  msg: |-
    initial configuration for dut
    =========================================
  
    updates:
  
    - path: /interface[name=system0]/subinterface[index=0]
      value:
       description: "No description"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:1:1::1/64"
  
  
    - path: /interface[name=ethernet-1/1]
      value:
       subinterface:
        index: 0
        description: "dut ~ r1"
  
    - path: /interface[name=ethernet-1/1]/subinterface[index=0]
      value:
       description: "dut ~ r1"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:3::1/64"
        neighbor-discovery:
         learn-unsolicited: link-local
        router-advertisement:
         router-role:
          admin-state: enable             # no ipv6 nd suppress-ra
          min-advertisement-interval: 4   # Leaving this at platform default 200..600 takes too long at startup
          _annotate_min-advertisement-interval: "Reduced from platform default 200s"
          max-advertisement-interval: 5
  
    - path: /interface[name=ethernet-1/2]
      value:
       subinterface:
        index: 0
        description: "dut ~ r2"
  
    - path: /interface[name=ethernet-1/2]/subinterface[index=0]
      value:
       description: "dut ~ r2"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:3:1::1/64"
        neighbor-discovery:
         learn-unsolicited: link-local
        router-advertisement:
         router-role:
          admin-state: enable             # no ipv6 nd suppress-ra
          min-advertisement-interval: 4   # Leaving this at platform default 200..600 takes too long at startup
          _annotate_min-advertisement-interval: "Reduced from platform default 200s"
          max-advertisement-interval: 5
  
    - path: /interface[name=ethernet-1/3]
      value:
       subinterface:
        index: 0
        description: "dut ~ r3"
  
    - path: /interface[name=ethernet-1/3]/subinterface[index=0]
      value:
       description: "dut ~ r3"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:3:2::1/64"
        neighbor-discovery:
         learn-unsolicited: link-local
        router-advertisement:
         router-role:
          admin-state: enable             # no ipv6 nd suppress-ra
          min-advertisement-interval: 4   # Leaving this at platform default 200..600 takes too long at startup
          _annotate_min-advertisement-interval: "Reduced from platform default 200s"
          max-advertisement-interval: 5
  
    - path: /interface[name=ethernet-1/4]
      value:
       subinterface:
        index: 0
        description: "dut ~ r4"
  
    - path: /interface[name=ethernet-1/4]/subinterface[index=0]
      value:
       description: "dut ~ r4"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:3:3::1/64"
        neighbor-discovery:
         learn-unsolicited: link-local
        router-advertisement:
         router-role:
          admin-state: enable             # no ipv6 nd suppress-ra
          min-advertisement-interval: 4   # Leaving this at platform default 200..600 takes too long at startup
          _annotate_min-advertisement-interval: "Reduced from platform default 200s"
          max-advertisement-interval: 5
  
    - path: /interface[name=lo0]
      value:
       subinterface:
        index: 1
        description: "VRF Loopback red"
  
    - path: /interface[name=lo0]/subinterface[index=1]
      value:
       description: "VRF Loopback red"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:c001:cafe::1/64"
        neighbor-discovery:
         learn-unsolicited: link-local
        router-advertisement:
         router-role:
          admin-state: enable             # no ipv6 nd suppress-ra
          min-advertisement-interval: 4   # Leaving this at platform default 200..600 takes too long at startup
          _annotate_min-advertisement-interval: "Reduced from platform default 200s"
          max-advertisement-interval: 5
  
    - path: /interface[name=lo0]
      value:
       subinterface:
        index: 2
        description: "VRF Loopback blue"
  
    - path: /interface[name=lo0]/subinterface[index=2]
      value:
       description: "VRF Loopback blue"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:c001:cafe::1/64"
        neighbor-discovery:
         learn-unsolicited: link-local
        router-advertisement:
         router-role:
          admin-state: enable             # no ipv6 nd suppress-ra
          min-advertisement-interval: 4   # Leaving this at platform default 200..600 takes too long at startup
          _annotate_min-advertisement-interval: "Reduced from platform default 200s"
          max-advertisement-interval: 5
  
  
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: system0.0
  
  
  
  
    # TODO: vdata.rd, vdata.import/export, vdata.af
    - path: /network-instance[name=blue]
      value:
       type: ip-vrf
       interface:
       - name: ethernet-1/3.0
    - path: /network-instance[name=blue]
      value:
       type: ip-vrf
       interface:
       - name: ethernet-1/4.0
    - path: /network-instance[name=blue]
      value:
       type: ip-vrf
       interface:
       - name: lo0.2
  
  
  
    # TODO: vdata.rd, vdata.import/export, vdata.af
    - path: /network-instance[name=red]
      value:
       type: ip-vrf
       interface:
       - name: ethernet-1/1.0
    - path: /network-instance[name=red]
      value:
       type: ip-vrf
       interface:
       - name: ethernet-1/2.0
    - path: /network-instance[name=red]
      value:
       type: ip-vrf
       interface:
       - name: lo0.1
ok: [r1] => 
  msg: |-
    initial configuration for r1
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "# Created by netlab initial" >>/tmp/hosts
    echo "2001:db8:1:1::1 dut" >>/tmp/hosts
    echo "2001:db8:3:2::1 2001:db8:3:3::1 2001:db8:c001:cafe::1 dut-blue" >>/tmp/hosts
    echo "2001:db8:3::1 2001:db8:3:1::1 2001:db8:c001:cafe::1 dut-red" >>/tmp/hosts
    echo "2001:db8:1:2::1 2001:db8:3::2 r1" >>/tmp/hosts
    echo "2001:db8:1:3::1 2001:db8:3:1::2 r2" >>/tmp/hosts
    echo "2001:db8:1:4::1 2001:db8:3:2::2 r3" >>/tmp/hosts
    echo "2001:db8:1:5::1 2001:db8:3:3::2 r4" >>/tmp/hosts
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts|sort >>/etc/hosts
  
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.autoconf=0
    sysctl -qw net.ipv6.conf.eth1.accept_ra=0
    ip link set eth1 down
    ip link set eth1 up
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1500
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r1
    !
    vrf mgmt
     exit-vrf
    !
    ipv6 forwarding
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ! no ip address
     ipv6 address 2001:db8:1:2::1/64
    !
    interface eth1
     no shutdown
     description r1 -> dut [external]
     ! no ip address
     ipv6 address 2001:db8:3::2/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r2] => 
  msg: |-
    initial configuration for r2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "# Created by netlab initial" >>/tmp/hosts
    echo "2001:db8:1:1::1 dut" >>/tmp/hosts
    echo "2001:db8:3:2::1 2001:db8:3:3::1 2001:db8:c001:cafe::1 dut-blue" >>/tmp/hosts
    echo "2001:db8:3::1 2001:db8:3:1::1 2001:db8:c001:cafe::1 dut-red" >>/tmp/hosts
    echo "2001:db8:1:2::1 2001:db8:3::2 r1" >>/tmp/hosts
    echo "2001:db8:1:3::1 2001:db8:3:1::2 r2" >>/tmp/hosts
    echo "2001:db8:1:4::1 2001:db8:3:2::2 r3" >>/tmp/hosts
    echo "2001:db8:1:5::1 2001:db8:3:3::2 r4" >>/tmp/hosts
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts|sort >>/etc/hosts
  
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.autoconf=0
    sysctl -qw net.ipv6.conf.eth1.accept_ra=0
    ip link set eth1 down
    ip link set eth1 up
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1500
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r2
    !
    vrf mgmt
     exit-vrf
    !
    ipv6 forwarding
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ! no ip address
     ipv6 address 2001:db8:1:3::1/64
    !
    interface eth1
     no shutdown
     description r2 -> dut [external]
     ! no ip address
     ipv6 address 2001:db8:3:1::2/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r4] => 
  msg: |-
    initial configuration for r4
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "# Created by netlab initial" >>/tmp/hosts
    echo "2001:db8:1:1::1 dut" >>/tmp/hosts
    echo "2001:db8:3:2::1 2001:db8:3:3::1 2001:db8:c001:cafe::1 dut-blue" >>/tmp/hosts
    echo "2001:db8:3::1 2001:db8:3:1::1 2001:db8:c001:cafe::1 dut-red" >>/tmp/hosts
    echo "2001:db8:1:2::1 2001:db8:3::2 r1" >>/tmp/hosts
    echo "2001:db8:1:3::1 2001:db8:3:1::2 r2" >>/tmp/hosts
    echo "2001:db8:1:4::1 2001:db8:3:2::2 r3" >>/tmp/hosts
    echo "2001:db8:1:5::1 2001:db8:3:3::2 r4" >>/tmp/hosts
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts|sort >>/etc/hosts
  
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.autoconf=0
    sysctl -qw net.ipv6.conf.eth1.accept_ra=0
    ip link set eth1 down
    ip link set eth1 up
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1500
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r4
    !
    vrf mgmt
     exit-vrf
    !
    ipv6 forwarding
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ! no ip address
     ipv6 address 2001:db8:1:5::1/64
    !
    interface eth1
     no shutdown
     description r4 -> dut [external]
     ! no ip address
     ipv6 address 2001:db8:3:3::2/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r3] => 
  msg: |-
    initial configuration for r3
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "# Created by netlab initial" >>/tmp/hosts
    echo "2001:db8:1:1::1 dut" >>/tmp/hosts
    echo "2001:db8:3:2::1 2001:db8:3:3::1 2001:db8:c001:cafe::1 dut-blue" >>/tmp/hosts
    echo "2001:db8:3::1 2001:db8:3:1::1 2001:db8:c001:cafe::1 dut-red" >>/tmp/hosts
    echo "2001:db8:1:2::1 2001:db8:3::2 r1" >>/tmp/hosts
    echo "2001:db8:1:3::1 2001:db8:3:1::2 r2" >>/tmp/hosts
    echo "2001:db8:1:4::1 2001:db8:3:2::2 r3" >>/tmp/hosts
    echo "2001:db8:1:5::1 2001:db8:3:3::2 r4" >>/tmp/hosts
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts|sort >>/etc/hosts
  
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.autoconf=0
    sysctl -qw net.ipv6.conf.eth1.accept_ra=0
    ip link set eth1 down
    ip link set eth1 up
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1500
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r3
    !
    vrf mgmt
     exit-vrf
    !
    ipv6 forwarding
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ! no ip address
     ipv6 address 2001:db8:1:4::1/64
    !
    interface eth1
     no shutdown
     description r3 -> dut [external]
     ! no ip address
     ipv6 address 2001:db8:3:2::2/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0

TASK [Find configuration deployment deploy_script for initial] *****************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/initial-clab.yml for r1, r2, r3, r4

TASK [tempfile] ****************************************************************
changed: [dut -> localhost]

TASK [template] ****************************************************************
changed: [dut -> localhost]

TASK [Generated JSON-RPC config based on /home/pipi/net101/tools/netsim/ansible/templates/initial/srlinux.j2] ***
skipping: [dut]

TASK [Update SRL initial node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/initial/srlinux.j2)] ***
changed: [dut]

TASK [debug] *******************************************************************
skipping: [dut]

TASK [file] ********************************************************************
changed: [dut -> localhost]

TASK [Attempt to load VRF kernel module] ***************************************
changed: [r2 -> localhost]
changed: [r3 -> localhost]
changed: [r4 -> localhost]
changed: [r1 -> localhost]

TASK [Disable FRR management VRF when modprobe fails] **************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for r1, r2, r3, r4

TASK [template] ****************************************************************
changed: [r1]
changed: [r4]
changed: [r2]
changed: [r3]

TASK [set_fact] ****************************************************************
ok: [r1]
ok: [r3]
ok: [r4]
ok: [r2]

TASK [run /tmp/config.sh to deploy initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
changed: [r1]
changed: [r4]
changed: [r3]
changed: [r2]

TASK [run vtysh to import initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

PLAY [Deploy module-specific configurations] ***********************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Deploy individual configuration modules] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4 => (item=bgp)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4 => (item=vrf)

TASK [Figure out whether to deploy the module bgp on current device] ***********
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r4]
ok: [r3]

TASK [Find configuration template for bgp] *************************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [r1] => 
  msg: |-
    bgp configuration for r1
    =========================================
    !
    router bgp 65101
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.2
    !
      neighbor 2001:db8:3::1 remote-as 65000
      neighbor 2001:db8:3::1 description dut
    !
     address-family ipv6 unicast
    !
      network 2001:db8:1:2::/64
    !
    !
    !
      neighbor 2001:db8:3::1 activate
      no neighbor 2001:db8:3::1 send-community all
      neighbor 2001:db8:3::1 send-community standard
      neighbor 2001:db8:3::1 send-community large
    !
    !
    !
    do write
ok: [dut] => 
  msg: |-
    bgp configuration for dut
    =========================================
    updates:
  
    - path: /routing-policy/policy[name=accept_all]
      value:
        default-action:
          policy-result: "accept"
  
    - path: /routing-policy/policy[name=next_hop_self_ebgp_ipv6]
      value:
       default-action:
        policy-result: "accept"
       statement:
       - name: set-nh-on-ebgp-routes
         match:
          protocol: bgp
          bgp:
           as-path-length:
            value: 1
            operator: "ge"
         action:
          policy-result: "accept"
          bgp:
           next-hop:
            set: "2001:db8:1:1::1"
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
       admin-state: enable
       autonomous-system: 65000
       router-id: 10.0.0.1
       ebgp-default-policy:
        export-reject-all: False
        import-reject-all: False
  
       afi-safi:
       - afi-safi-name: ipv6-unicast
         admin-state: enable
         multipath:
          max-paths-level-1: 64
          max-paths-level-2: 64 # indirect nexthops
  
    - path: /routing-policy/prefix-set[name=default_export]
      value:
        prefix: [] # Make sure it exists
  
    - path: /routing-policy/policy[name=default_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
            prefix-set: default_export
          action:
            policy-result: accept
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: accept
    - path: /routing-policy/prefix-set[name=default_export]
      value:
        prefix:
        - ip-prefix: 2001:db8:1:1::/64
          mask-length-range: exact
ok: [r4] => 
  msg: |-
    bgp configuration for r4
    =========================================
    !
    router bgp 65104
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.5
    !
      neighbor 2001:db8:3:3::1 remote-as 65000
      neighbor 2001:db8:3:3::1 description dut
    !
     address-family ipv6 unicast
    !
      network 2001:db8:1:5::/64
    !
    !
    !
      neighbor 2001:db8:3:3::1 activate
      no neighbor 2001:db8:3:3::1 send-community all
      neighbor 2001:db8:3:3::1 send-community standard
      neighbor 2001:db8:3:3::1 send-community large
    !
    !
    !
    do write
ok: [r3] => 
  msg: |-
    bgp configuration for r3
    =========================================
    !
    router bgp 65103
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.4
    !
      neighbor 2001:db8:3:2::1 remote-as 65000
      neighbor 2001:db8:3:2::1 description dut
    !
     address-family ipv6 unicast
    !
      network 2001:db8:1:4::/64
    !
    !
    !
      neighbor 2001:db8:3:2::1 activate
      no neighbor 2001:db8:3:2::1 send-community all
      neighbor 2001:db8:3:2::1 send-community standard
      neighbor 2001:db8:3:2::1 send-community large
    !
    !
    !
    do write
ok: [r2] => 
  msg: |-
    bgp configuration for r2
    =========================================
    !
    router bgp 65102
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.3
    !
      neighbor 2001:db8:3:1::1 remote-as 65000
      neighbor 2001:db8:3:1::1 description dut
    !
     address-family ipv6 unicast
    !
      network 2001:db8:1:3::/64
    !
    !
    !
      neighbor 2001:db8:3:1::1 activate
      no neighbor 2001:db8:3:1::1 send-community all
      neighbor 2001:db8:3:1::1 send-community standard
      neighbor 2001:db8:3:1::1 send-community large
    !
    !
    !
    do write

TASK [Find configuration deployment deploy_script for bgp] *********************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Deploy bgp configuration] ************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for r1, r2, r3, r4

TASK [tempfile] ****************************************************************
changed: [dut -> localhost]

TASK [template] ****************************************************************
changed: [dut -> localhost]

TASK [Generated JSON-RPC config based on /home/pipi/net101/tools/netsim/ansible/templates/bgp/srlinux.j2] ***
skipping: [dut]

TASK [Update SRL bgp node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/bgp/srlinux.j2)] ***
changed: [dut]

TASK [debug] *******************************************************************
skipping: [dut]

TASK [file] ********************************************************************
changed: [dut -> localhost]

TASK [template] ****************************************************************
changed: [r1]
changed: [r2]
changed: [r3]
changed: [r4]

TASK [set_fact] ****************************************************************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [run /tmp/config.sh to deploy bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [run vtysh to import bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
changed: [r2]
changed: [r1]
changed: [r3]
changed: [r4]

TASK [Figure out whether to deploy the module vrf on current device] ***********
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Find configuration template for vrf] *************************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
ok: [dut]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
ok: [dut] => 
  msg: |-
    vrf configuration for dut
    =========================================
  
    updates:
  
    - path: /network-instance[name=blue]
      value:
       type: ip-vrf
  
  
  
    - path: /routing-policy/community-set[name=C65000_2]
      value:
       member:
       - "target:65000:2" # Single member, else matching is AND
  
    - path: /routing-policy/community-set[name=blue_export]
      value:
       member:
       - "target:65000:2"
  
    - path: /network-instance[name=blue]/protocols/bgp
      value:
       admin-state: enable
       autonomous-system: 65000
       router-id: 10.0.0.1
       ebgp-default-policy:
        export-reject-all: False
        import-reject-all: False
  
       afi-safi:
       - afi-safi-name: ipv6-unicast
         admin-state: enable
         multipath:
          max-paths-level-1: 64
          max-paths-level-2: 64 # indirect nexthops
  
    - path: /routing-policy/prefix-set[name=blue_export]
      value:
        prefix: [] # Make sure it exists
  
    - path: /routing-policy/policy[name=blue_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
            prefix-set: blue_export
          action:
            policy-result: accept
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: accept
        - name: local
          match:
            protocol: local
          action:
            policy-result: accept
        - name: ospfv2
          match:
            protocol: ospfv2
          action:
            policy-result: accept
        - name: ospfv3
          match:
            protocol: ospfv3
          action:
            policy-result: accept
  
  
  
  
  
  
    - path: /network-instance[name=blue]/protocols/bgp/group[group-name=ebgp]
      value:
       admin-state: enable
       afi-safi:
       - afi-safi-name: ipv4-unicast
         admin-state: enable
       - afi-safi-name: ipv6-unicast
         admin-state: enable
  
       timers:
        connect-retry: 10
        _annotate_connect-retry: "Reduce default 120s to 10s"
        minimum-advertisement-interval: 1
       send-community:
        standard: True
        large: True
        _annotate_large: "Assuming 'standard' implies 'large' here"
       import-policy: accept_all
       export-policy: blue_export
  
  
    - path: /network-instance[name=blue]/protocols/bgp
      value:
       neighbor:
       - peer-address: "2001:db8:3:2::2"
         description: r3
         peer-group: ebgp
         afi-safi:
         - afi-safi-name: ipv4-unicast
           admin-state: enable
         - afi-safi-name: ipv6-unicast
           admin-state: enable
  
         peer-as: 65103
  
  
    - path: /network-instance[name=blue]/protocols/bgp/group[group-name=ebgp]
      value:
       admin-state: enable
       afi-safi:
       - afi-safi-name: ipv4-unicast
         admin-state: enable
       - afi-safi-name: ipv6-unicast
         admin-state: enable
  
       timers:
        connect-retry: 10
        _annotate_connect-retry: "Reduce default 120s to 10s"
        minimum-advertisement-interval: 1
       send-community:
        standard: True
        large: True
        _annotate_large: "Assuming 'standard' implies 'large' here"
       import-policy: accept_all
       export-policy: blue_export
  
  
    - path: /network-instance[name=blue]/protocols/bgp
      value:
       neighbor:
       - peer-address: "2001:db8:3:3::2"
         description: r4
         peer-group: ebgp
         afi-safi:
         - afi-safi-name: ipv4-unicast
           admin-state: enable
         - afi-safi-name: ipv6-unicast
           admin-state: enable
  
         peer-as: 65104
  
  
  
  
  
    - path: /network-instance[name=blue]/protocols/bgp-vpn
      value:
       bgp-instance:
       - id: 1
         route-distinguisher:
          rd: "65000:2"
  
    - path: /network-instance[name=blue]/inter-instance-policies
      value:
       apply-policy:
        export-policy: "blue_vpn_export"
        import-policy: "blue_vpn_import"
  
    - path: /routing-policy/policy[name=blue_vpn_export]
      value:
       default-action:
        policy-result: "accept"
        bgp:
         communities:
          add: "blue_export"
  
    - path: /routing-policy/policy[name=blue_vpn_import]
      value:
       default-action:
        policy-result: "reject"
       statement:
       - name: 11
         match:
          bgp:
           community-set: "C65000_2"
         action:
          policy-result: "accept"
  
  
    - path: /network-instance[name=red]
      value:
       type: ip-vrf
  
  
  
    - path: /routing-policy/community-set[name=C65000_1]
      value:
       member:
       - "target:65000:1" # Single member, else matching is AND
  
    - path: /routing-policy/community-set[name=red_export]
      value:
       member:
       - "target:65000:1"
  
    - path: /network-instance[name=red]/protocols/bgp
      value:
       admin-state: enable
       autonomous-system: 65000
       router-id: 10.0.0.1
       ebgp-default-policy:
        export-reject-all: False
        import-reject-all: False
  
       afi-safi:
       - afi-safi-name: ipv6-unicast
         admin-state: enable
         multipath:
          max-paths-level-1: 64
          max-paths-level-2: 64 # indirect nexthops
  
    - path: /routing-policy/prefix-set[name=red_export]
      value:
        prefix: [] # Make sure it exists
  
    - path: /routing-policy/policy[name=red_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
            prefix-set: red_export
          action:
            policy-result: accept
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: accept
        - name: local
          match:
            protocol: local
          action:
            policy-result: accept
        - name: ospfv2
          match:
            protocol: ospfv2
          action:
            policy-result: accept
        - name: ospfv3
          match:
            protocol: ospfv3
          action:
            policy-result: accept
  
  
  
  
  
  
    - path: /network-instance[name=red]/protocols/bgp/group[group-name=ebgp]
      value:
       admin-state: enable
       afi-safi:
       - afi-safi-name: ipv4-unicast
         admin-state: enable
       - afi-safi-name: ipv6-unicast
         admin-state: enable
  
       timers:
        connect-retry: 10
        _annotate_connect-retry: "Reduce default 120s to 10s"
        minimum-advertisement-interval: 1
       send-community:
        standard: True
        large: True
        _annotate_large: "Assuming 'standard' implies 'large' here"
       import-policy: accept_all
       export-policy: red_export
  
  
    - path: /network-instance[name=red]/protocols/bgp
      value:
       neighbor:
       - peer-address: "2001:db8:3::2"
         description: r1
         peer-group: ebgp
         afi-safi:
         - afi-safi-name: ipv4-unicast
           admin-state: enable
         - afi-safi-name: ipv6-unicast
           admin-state: enable
  
         peer-as: 65101
  
  
    - path: /network-instance[name=red]/protocols/bgp/group[group-name=ebgp]
      value:
       admin-state: enable
       afi-safi:
       - afi-safi-name: ipv4-unicast
         admin-state: enable
       - afi-safi-name: ipv6-unicast
         admin-state: enable
  
       timers:
        connect-retry: 10
        _annotate_connect-retry: "Reduce default 120s to 10s"
        minimum-advertisement-interval: 1
       send-community:
        standard: True
        large: True
        _annotate_large: "Assuming 'standard' implies 'large' here"
       import-policy: accept_all
       export-policy: red_export
  
  
    - path: /network-instance[name=red]/protocols/bgp
      value:
       neighbor:
       - peer-address: "2001:db8:3:1::2"
         description: r2
         peer-group: ebgp
         afi-safi:
         - afi-safi-name: ipv4-unicast
           admin-state: enable
         - afi-safi-name: ipv6-unicast
           admin-state: enable
  
         peer-as: 65102
  
  
  
  
  
    - path: /network-instance[name=red]/protocols/bgp-vpn
      value:
       bgp-instance:
       - id: 1
         route-distinguisher:
          rd: "65000:1"
  
    - path: /network-instance[name=red]/inter-instance-policies
      value:
       apply-policy:
        export-policy: "red_vpn_export"
        import-policy: "red_vpn_import"
  
    - path: /routing-policy/policy[name=red_vpn_export]
      value:
       default-action:
        policy-result: "accept"
        bgp:
         communities:
          add: "red_export"
  
    - path: /routing-policy/policy[name=red_vpn_import]
      value:
       default-action:
        policy-result: "reject"
       statement:
       - name: 11
         match:
          bgp:
           community-set: "C65000_1"
         action:
          policy-result: "accept"

TASK [Find configuration deployment deploy_script for vrf] *********************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
ok: [dut]

TASK [Deploy vrf configuration] ************************************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for dut

TASK [tempfile] ****************************************************************
changed: [dut -> localhost]

TASK [template] ****************************************************************
changed: [dut -> localhost]

TASK [Generated JSON-RPC config based on /home/pipi/net101/tools/netsim/ansible/templates/vrf/srlinux.j2] ***
skipping: [dut]

TASK [Update SRL vrf node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/vrf/srlinux.j2)] ***
changed: [dut]

TASK [debug] *******************************************************************
skipping: [dut]

TASK [file] ********************************************************************
changed: [dut -> localhost]

PLAY [Deploy custom deployment templates] **************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
dut                        : ok=33   changed=12   unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
r1                         : ok=25   changed=5    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
r2                         : ok=25   changed=5    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
r3                         : ok=25   changed=5    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
r4                         : ok=25   changed=5    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   



The device under test has two VRFs with two interfaces in each VRF.
Routers are attached to those interfaces and run BGP with device under test.
Assuming the multi-vrf BGP test case succeeded, this one adds VRF loopback
interfaces advertised into BGP with network statements.

* r1 and r2 should be able to ping each other and rtr VRF loopback
* r3 and r4 should be able to ping each other and rtr VRF loopback
* r1 should not be able to reach r3

