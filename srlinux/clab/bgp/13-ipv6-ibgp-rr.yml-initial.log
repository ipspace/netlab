[WARNING]: Could not match supplied host pattern, ignoring: unprovisioned
[WARNING]: Found variable using reserved name: hosts

PLAY [Deploy initial device configuration] *************************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Find device readiness script] ********************************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Wait for device to become ready] *****************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [Normalize config on bridge-like devices] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, rr2, x1

TASK [Figure out whether to deploy the module normalize on current device] *****
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Find configuration template for normalize] *******************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [Find configuration deployment deploy_script for normalize] ***************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [Deploy normalize configuration] ******************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, rr2, x1

TASK [Figure out whether to deploy the module initial on current device] *******
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Find configuration template for initial] *********************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [Find configuration deployment deploy_script for initial] *****************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [dut] => 
  msg: |-
    initial configuration for dut
    =========================================
  
    updates:
    - path: /system/mtu
      value:
       default-port-mtu: 1514
       default-l2-mtu: 1514
       default-ip-mtu: 1500
       _annotate_default-ip-mtu: "Custom system wide setting, overrides default 1500"
  
    - path: /interface[name=system0]/subinterface[index=0]
      value:
       description: "No description"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:1:1::1/64"
  
  
    - path: /interface[name=ethernet-1/1]
      value:
       subinterface:
        index: 0
        description: "dut ~ r1"
  
    - path: /interface[name=ethernet-1/1]/subinterface[index=0]
      value:
       description: "dut ~ r1"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:3::1/64"
        neighbor-discovery:
         learn-unsolicited: link-local
        router-advertisement:
         router-role:
          admin-state: enable             # no ipv6 nd suppress-ra
          min-advertisement-interval: 4   # Leaving this at platform default 200..600 takes too long at startup
          _annotate_min-advertisement-interval: "Reduced from platform default 200s"
          max-advertisement-interval: 5
  
    - path: /interface[name=ethernet-1/2]
      value:
       subinterface:
        index: 0
        description: "dut ~ x1"
  
    - path: /interface[name=ethernet-1/2]/subinterface[index=0]
      value:
       description: "dut ~ x1"
       ipv6:
        admin-state: enable
        address:
        - ip-prefix: "2001:db8:3:3::1/64"
        neighbor-discovery:
         learn-unsolicited: link-local
        router-advertisement:
         router-role:
          admin-state: enable             # no ipv6 nd suppress-ra
          min-advertisement-interval: 4   # Leaving this at platform default 200..600 takes too long at startup
          _annotate_min-advertisement-interval: "Reduced from platform default 200s"
          max-advertisement-interval: 5
  
  
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: system0.0
  
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: ethernet-1/1.0
    - path: /network-instance[name=default]
      value:
       type: default
       interface:
       - name: ethernet-1/2.0
ok: [r1] => 
  msg: |-
    initial configuration for r1
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
    if [ ! -e /sys/class/net/eth4 ]; then
      if [ ! -e /sys/devices/virtual/net/eth4 ]; then
        ip link add eth4 type dummy
        ip link set dev eth4 up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.autoconf=0
    sysctl -qw net.ipv6.conf.eth1.accept_ra=0
    ip link set eth1 down
    ip link set eth1 up
    ip link set dev eth1 mtu 1500
    sysctl -qw net.ipv6.conf.eth2.autoconf=0
    sysctl -qw net.ipv6.conf.eth2.accept_ra=0
    ip link set eth2 down
    ip link set eth2 up
    ip link set dev eth2 mtu 1500
    sysctl -qw net.ipv6.conf.eth3.autoconf=0
    sysctl -qw net.ipv6.conf.eth3.accept_ra=0
    ip link set eth3 down
    ip link set eth3 up
    ip link set dev eth3 mtu 1500
    sysctl -qw net.ipv6.conf.eth4.autoconf=0
    sysctl -qw net.ipv6.conf.eth4.accept_ra=0
    ip link set eth4 down
    ip link set eth4 up
    ip link set dev eth4 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r1
    !
    vrf mgmt
     exit-vrf
    !
    ipv6 forwarding
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ! no ip address
     ipv6 address 2001:db8:1:a::1/64
    !
    interface eth1
     no shutdown
     description r1 -> dut
     ! no ip address
     ipv6 address 2001:db8:3::2/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    interface eth2
     no shutdown
     description r1 -> rr2
     ! no ip address
     ipv6 address 2001:db8:3:1::1/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    interface eth3
     no shutdown
     description r1 -> r2
     ! no ip address
     ipv6 address 2001:db8:3:2::1/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    interface eth4
     no shutdown
     description r1 -> stub [stub]
     ! no ip address
     ipv6 address 2001:db8:cafe:1::a/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r2] => 
  msg: |-
    initial configuration for r2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.autoconf=0
    sysctl -qw net.ipv6.conf.eth1.accept_ra=0
    ip link set eth1 down
    ip link set eth1 up
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r2
    !
    vrf mgmt
     exit-vrf
    !
    ipv6 forwarding
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ! no ip address
     ipv6 address 2001:db8:1:3::1/64
    !
    interface eth1
     no shutdown
     description r2 -> r1
     ! no ip address
     ipv6 address 2001:db8:3:2::2/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [x1] => 
  msg: |-
    initial configuration for x1
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.autoconf=0
    sysctl -qw net.ipv6.conf.eth1.accept_ra=0
    ip link set eth1 down
    ip link set eth1 up
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname x1
    !
    vrf mgmt
     exit-vrf
    !
    ipv6 forwarding
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ! no ip address
     ipv6 address 2001:db8:cafe:e::1/64
    !
    interface eth1
     no shutdown
     description x1 -> dut [external]
     ! no ip address
     ipv6 address 2001:db8:3:3::2/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [rr2] => 
  msg: |-
    initial configuration for rr2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.autoconf=0
    sysctl -qw net.ipv6.conf.eth1.accept_ra=0
    ip link set eth1 down
    ip link set eth1 up
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname rr2
    !
    vrf mgmt
     exit-vrf
    !
    ipv6 forwarding
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ! no ip address
     ipv6 address 2001:db8:1:2::1/64
    !
    interface eth1
     no shutdown
     description rr2 -> r1
     ! no ip address
     ipv6 address 2001:db8:3:1::2/64
     ipv6 nd ra-interval 5
     no ipv6 nd suppress-ra
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/initial-clab.yml for r1, r2, rr2, x1

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [dut]

TASK [Update SRL initial node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/initial/srlinux.j2)] ***
changed: [dut]

TASK [debug] *******************************************************************
skipping: [dut]

TASK [Attempt to load VRF kernel module] ***************************************
changed: [r1 -> localhost]

TASK [Disable FRR management VRF when modprobe fails] **************************
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for r1, r2, rr2, x1

TASK [template] ****************************************************************
changed: [r1]
changed: [rr2]
changed: [x1]
changed: [r2]

TASK [set_fact] ****************************************************************
ok: [r2]
ok: [r1]
ok: [rr2]
ok: [x1]

TASK [run /tmp/config.sh to deploy initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
changed: [r1]
changed: [rr2]
changed: [r2]
changed: [x1]

TASK [run vtysh to import initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

PLAY [Deploy module-specific configurations] ***********************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Deploy individual configuration modules] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, rr2, x1 => (item=bgp)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, rr2, x1 => (item=ospf)

TASK [Figure out whether to deploy the module bgp on current device] ***********
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Find configuration template for bgp] *************************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [Find configuration deployment deploy_script for bgp] *********************
ok: [dut]
ok: [r1]
ok: [rr2]
ok: [r2]
ok: [x1]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [r1] => 
  msg: |-
    bgp configuration for r1
    =========================================
    !
    router bgp 65000
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.10
    !
      neighbor 2001:db8:1:1::1 remote-as 65000
      neighbor 2001:db8:1:1::1 description dut
      neighbor 2001:db8:1:1::1 update-source lo
    !
      neighbor 2001:db8:1:2::1 remote-as 65000
      neighbor 2001:db8:1:2::1 description rr2
      neighbor 2001:db8:1:2::1 update-source lo
    !
     address-family ipv6 unicast
    !
  
    !
      network 2001:db8:1:a::/64
    !
      network 2001:db8:cafe:1::/64
    !
    !
      neighbor 2001:db8:1:1::1 activate
      neighbor 2001:db8:1:1::1 next-hop-self
      no neighbor 2001:db8:1:1::1 send-community all
      neighbor 2001:db8:1:1::1 send-community standard
      neighbor 2001:db8:1:1::1 send-community large
      neighbor 2001:db8:1:1::1 send-community extended
    !
      neighbor 2001:db8:1:2::1 activate
      neighbor 2001:db8:1:2::1 next-hop-self
      no neighbor 2001:db8:1:2::1 send-community all
      neighbor 2001:db8:1:2::1 send-community standard
      neighbor 2001:db8:1:2::1 send-community large
      neighbor 2001:db8:1:2::1 send-community extended
    !
    !
    !
    do write
ok: [dut] => 
  msg: |-
    bgp configuration for dut
    =========================================
    updates:
  
    - path: /routing-policy/policy[name=accept_all]
      value:
        default-action:
          policy-result: accept
  
    - path: /routing-policy/community-set[name=ibgp-mark]
      value:
        member: [ "65536:0:65536" ]
  
    - path: /routing-policy/policy[name=ibgp-mark]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: mark-ibgp-routes
          action:
            bgp:
              communities:
                add: ibgp-mark
            policy-result: accept
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix: [] # Make sure it exists
  
    - path: /routing-policy/policy[name=default_bgp_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
            prefix-set: default_bgp_advertise
          action:
            policy-result: next-policy
        - name: bgp
          match:
            protocol: bgp
          action:
            policy-result: next-policy
            bgp:
              communities:
                remove:
                  ibgp-mark
  
  
    - path: /routing-policy/policy[name=default_ibgp-nhs_export]
      value:
        default-action:
          policy-result: reject
        statement:
        - name: prefixes
          match:
            prefix-set: default_bgp_advertise
          action:
            policy-result: next-policy
        - name: rr-next-hop-unchanged
          match:
            protocol: bgp
            bgp:
              community-set: ibgp-mark
          action:
            policy-result: next-policy
            bgp:
              communities:
                remove:
                  ibgp-mark
        - name: ebgp-next-hop-self
          match:
            protocol: bgp
          action:
            policy-result: next-policy
            bgp:
              next-hop:
                set: self
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        admin-state: enable
        autonomous-system: 65000
        router-id: 10.0.0.1
        ebgp-default-policy:
          export-reject-all: False
          import-reject-all: False
  
        afi-safi:
        - afi-safi-name: ipv6-unicast
          admin-state: enable
  
    - path: /routing-policy/prefix-set[name=default_bgp_advertise]
      value:
        prefix:
        - ip-prefix: 2001:db8:1:1::/64
          mask-length-range: exact
  
  
  
  
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ibgp-ipv6]
      value:
        admin-state: enable
    # neighbor: {'_source_intf': {'ifindex': 0, 'ifname': 'lo0.0', 'ipv6': '2001:db8:1:1::1/64', 'neighbors': [], 'type': 'loopback', 'virtual_interface': True}, 'activate': {'ipv6': True}, 'as': 65000, 'ipv6': '2001:db8:1:2::1', 'name': 'rr2', 'rr': True, 'type': 'ibgp'}
    # ipv4: True
    # ipv6: True
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: disable
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: enable
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
        peer-as: 65000
        transport:
          local-address: 2001:db8:1:1::1
        route-reflector:
          cluster-id: 10.0.0.42
          client: True
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "2001:db8:1:2::1"
          description: rr2
          peer-group: ibgp-ipv6
      # neighbor: {'_source_intf': {'ifindex': 0, 'ifname': 'lo0.0', 'ipv6': '2001:db8:1:1::1/64', 'neighbors': [], 'type': 'loopback', 'virtual_interface': True}, 'activate': {'ipv6': True}, 'as': 65000, 'ipv6': '2001:db8:1:2::1', 'name': 'rr2', 'rr': True, 'type': 'ibgp'}
      # ipv4: True
      # ipv6: True
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: disable
          - afi-safi-name: ipv6-unicast
            admin-state: enable
  
          route-reflector:
            client: False # Don't reflect routes between ibgp route reflectors
          transport:
            passive-mode: False
            _annotate_passive-mode: "Connect actively to other Route Reflectors"
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ibgp-ipv6]
      value:
        admin-state: enable
    # neighbor: {'_source_intf': {'ifindex': 0, 'ifname': 'lo0.0', 'ipv6': '2001:db8:1:1::1/64', 'neighbors': [], 'type': 'loopback', 'virtual_interface': True}, 'activate': {'ipv6': True}, 'as': 65000, 'ipv6': '2001:db8:1:a::1', 'name': 'r1', 'type': 'ibgp'}
    # ipv4: True
    # ipv6: True
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: disable
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: enable
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
        peer-as: 65000
        transport:
          local-address: 2001:db8:1:1::1
        route-reflector:
          cluster-id: 10.0.0.42
          client: True
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "2001:db8:1:a::1"
          description: r1
          peer-group: ibgp-ipv6
      # neighbor: {'_source_intf': {'ifindex': 0, 'ifname': 'lo0.0', 'ipv6': '2001:db8:1:1::1/64', 'neighbors': [], 'type': 'loopback', 'virtual_interface': True}, 'activate': {'ipv6': True}, 'as': 65000, 'ipv6': '2001:db8:1:a::1', 'name': 'r1', 'type': 'ibgp'}
      # ipv4: True
      # ipv6: True
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: disable
          - afi-safi-name: ipv6-unicast
            admin-state: enable
  
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ibgp-ipv6]
      value:
        admin-state: enable
    # neighbor: {'_source_intf': {'ifindex': 0, 'ifname': 'lo0.0', 'ipv6': '2001:db8:1:1::1/64', 'neighbors': [], 'type': 'loopback', 'virtual_interface': True}, 'activate': {'ipv6': True}, 'as': 65000, 'ipv6': '2001:db8:1:3::1', 'name': 'r2', 'type': 'ibgp'}
    # ipv4: True
    # ipv6: True
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: disable
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: enable
          import-policy: ['ibgp-mark']
          export-policy: ['default_ibgp-nhs_export', 'accept_all']
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
        peer-as: 65000
        transport:
          local-address: 2001:db8:1:1::1
        route-reflector:
          cluster-id: 10.0.0.42
          client: True
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "2001:db8:1:3::1"
          description: r2
          peer-group: ibgp-ipv6
      # neighbor: {'_source_intf': {'ifindex': 0, 'ifname': 'lo0.0', 'ipv6': '2001:db8:1:1::1/64', 'neighbors': [], 'type': 'loopback', 'virtual_interface': True}, 'activate': {'ipv6': True}, 'as': 65000, 'ipv6': '2001:db8:1:3::1', 'name': 'r2', 'type': 'ibgp'}
      # ipv4: True
      # ipv6: True
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: disable
          - afi-safi-name: ipv6-unicast
            admin-state: enable
  
  
    - path: /network-instance[name=default]/protocols/bgp/group[group-name=ebgp]
      value:
        admin-state: enable
    # neighbor: {'activate': {'ipv6': True}, 'as': 65101, 'ifindex': 2, 'ipv6': '2001:db8:3:3::2', 'name': 'x1', 'type': 'ebgp'}
    # ipv4: True
    # ipv6: True
        afi-safi:
        - afi-safi-name: ipv4-unicast
          admin-state: disable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
        - afi-safi-name: ipv6-unicast
          admin-state: enable
          import-policy: ['accept_all']
          export-policy: ['default_bgp_export', 'accept_all']
  
        timers:
          connect-retry: 10
          _annotate_connect-retry: "Reduce default 120s to 10s"
          minimum-advertisement-interval: 1
        send-community:
          standard: True
          large: True
          _annotate_large: "Assuming 'standard' implies 'large' here"
  
  
    - path: /network-instance[name=default]/protocols/bgp
      value:
        neighbor:
        - peer-address: "2001:db8:3:3::2"
          description: x1
          peer-group: ebgp
      # neighbor: {'activate': {'ipv6': True}, 'as': 65101, 'ifindex': 2, 'ipv6': '2001:db8:3:3::2', 'name': 'x1', 'type': 'ebgp'}
      # ipv4: True
      # ipv6: True
          afi-safi:
          - afi-safi-name: ipv4-unicast
            admin-state: disable
          - afi-safi-name: ipv6-unicast
            admin-state: enable
  
          peer-as: 65101
ok: [x1] => 
  msg: |-
    bgp configuration for x1
    =========================================
    !
    router bgp 65101
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.4
    !
      neighbor 2001:db8:3:3::1 remote-as 65000
      neighbor 2001:db8:3:3::1 description dut
    !
     address-family ipv6 unicast
    !
  
    !
      network 2001:db8:cafe:e::/64
    !
    !
    !
      neighbor 2001:db8:3:3::1 activate
      no neighbor 2001:db8:3:3::1 send-community all
      neighbor 2001:db8:3:3::1 send-community standard
      neighbor 2001:db8:3:3::1 send-community large
    !
    !
    !
    do write
ok: [r2] => 
  msg: |-
    bgp configuration for r2
    =========================================
    !
    router bgp 65000
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.3
    !
      neighbor 2001:db8:1:1::1 remote-as 65000
      neighbor 2001:db8:1:1::1 description dut
      neighbor 2001:db8:1:1::1 update-source lo
    !
      neighbor 2001:db8:1:2::1 remote-as 65000
      neighbor 2001:db8:1:2::1 description rr2
      neighbor 2001:db8:1:2::1 update-source lo
    !
     address-family ipv6 unicast
    !
  
    !
      network 2001:db8:1:3::/64
    !
    !
    !
      neighbor 2001:db8:1:1::1 activate
      neighbor 2001:db8:1:1::1 next-hop-self
      no neighbor 2001:db8:1:1::1 send-community all
      neighbor 2001:db8:1:1::1 send-community standard
      neighbor 2001:db8:1:1::1 send-community large
      neighbor 2001:db8:1:1::1 send-community extended
    !
      neighbor 2001:db8:1:2::1 activate
      neighbor 2001:db8:1:2::1 next-hop-self
      no neighbor 2001:db8:1:2::1 send-community all
      neighbor 2001:db8:1:2::1 send-community standard
      neighbor 2001:db8:1:2::1 send-community large
      neighbor 2001:db8:1:2::1 send-community extended
    !
    !
    !
    do write
ok: [rr2] => 
  msg: |-
    bgp configuration for rr2
    =========================================
    !
    router bgp 65000
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.2
      bgp cluster-id 10.0.0.43
    !
      neighbor 2001:db8:1:1::1 remote-as 65000
      neighbor 2001:db8:1:1::1 description dut
      neighbor 2001:db8:1:1::1 update-source lo
    !
      neighbor 2001:db8:1:a::1 remote-as 65000
      neighbor 2001:db8:1:a::1 description r1
      neighbor 2001:db8:1:a::1 update-source lo
    !
      neighbor 2001:db8:1:3::1 remote-as 65000
      neighbor 2001:db8:1:3::1 description r2
      neighbor 2001:db8:1:3::1 update-source lo
    !
     address-family ipv6 unicast
    !
  
    !
      network 2001:db8:1:2::/64
    !
    !
    !
      neighbor 2001:db8:1:1::1 activate
      neighbor 2001:db8:1:1::1 next-hop-self
      no neighbor 2001:db8:1:1::1 send-community all
      neighbor 2001:db8:1:1::1 send-community standard
      neighbor 2001:db8:1:1::1 send-community large
      neighbor 2001:db8:1:1::1 send-community extended
    !
      neighbor 2001:db8:1:a::1 activate
      neighbor 2001:db8:1:a::1 next-hop-self
      neighbor 2001:db8:1:a::1 route-reflector-client
      no neighbor 2001:db8:1:a::1 send-community all
      neighbor 2001:db8:1:a::1 send-community standard
      neighbor 2001:db8:1:a::1 send-community large
      neighbor 2001:db8:1:a::1 send-community extended
    !
      neighbor 2001:db8:1:3::1 activate
      neighbor 2001:db8:1:3::1 next-hop-self
      neighbor 2001:db8:1:3::1 route-reflector-client
      no neighbor 2001:db8:1:3::1 send-community all
      neighbor 2001:db8:1:3::1 send-community standard
      neighbor 2001:db8:1:3::1 send-community large
      neighbor 2001:db8:1:3::1 send-community extended
    !
    !
    !
    do write

TASK [Deploy bgp configuration] ************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for r1, r2, rr2, x1

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [dut]

TASK [Update SRL bgp node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/bgp/srlinux.j2)] ***
changed: [dut]

TASK [debug] *******************************************************************
skipping: [dut]

TASK [template] ****************************************************************
changed: [r1]
changed: [r2]
changed: [x1]
changed: [rr2]

TASK [set_fact] ****************************************************************
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [run /tmp/config.sh to deploy bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [run vtysh to import bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
changed: [r1]
changed: [r2]
changed: [rr2]
changed: [x1]

TASK [Figure out whether to deploy the module ospf on current device] **********
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]
ok: [x1]

TASK [Find configuration template for ospf] ************************************
ok: [dut]
skipping: [x1]
ok: [r1]
ok: [r2]
ok: [rr2]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [rr2]
skipping: [x1]

TASK [Find configuration deployment deploy_script for ospf] ********************
skipping: [x1]
ok: [dut]
ok: [r1]
ok: [r2]
ok: [rr2]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [x1]
ok: [dut] => 
  msg: |-
    ospf configuration for dut
    =========================================
    updates:
  
  
    - path: /network-instance[name=default]
      value:
        router-id: 10.0.0.1
        protocols:
          ospf:
            instance:
            - name: "1"
              version: ospf-v3
              address-family: ipv6-unicast
              admin-state: enable
              max-ecmp-paths: 64
              area:
              - area-id: 0.0.0.0
                interface:
                - interface-name: system0.0
                  passive: True
              - area-id: 0.0.0.0
                interface:
                - interface-name: ethernet-1/1.0
                  interface-type: "point-to-point"
                  failure-detection:
                    enable-bfd: False
           # OSPF not configured on external interface ethernet-1/2
ok: [r1] => 
  msg: |-
    ospf configuration for r1
    =========================================
    !
    ! OSPFv3 FRR configuration
    !
    interface lo
    !
     ipv6 ospf6 area 0.0.0.0
    !
    interface eth1
    ! r1 -> dut
     ipv6 ospf6 area 0.0.0.0
     ipv6 ospf6 network point-to-point
    !
    interface eth2
    ! r1 -> rr2
     ipv6 ospf6 area 0.0.0.0
     ipv6 ospf6 network point-to-point
    !
    interface eth3
    ! r1 -> r2
     ipv6 ospf6 area 0.0.0.0
     ipv6 ospf6 network point-to-point
    !
    !
    router ospf6
     ospf6 router-id 10.0.0.10
     timers lsa min-arrival 100
     timers throttle spf 10 50 500
  
  
    exit
  
    !
    do write
ok: [r2] => 
  msg: |-
    ospf configuration for r2
    =========================================
    !
    ! OSPFv3 FRR configuration
    !
    interface lo
    !
     ipv6 ospf6 area 0.0.0.0
    !
    interface eth1
    ! r2 -> r1
     ipv6 ospf6 area 0.0.0.0
     ipv6 ospf6 network point-to-point
    !
    !
    router ospf6
     ospf6 router-id 10.0.0.3
     timers lsa min-arrival 100
     timers throttle spf 10 50 500
  
  
    exit
  
    !
    do write
ok: [rr2] => 
  msg: |-
    ospf configuration for rr2
    =========================================
    !
    ! OSPFv3 FRR configuration
    !
    interface lo
    !
     ipv6 ospf6 area 0.0.0.0
    !
    interface eth1
    ! rr2 -> r1
     ipv6 ospf6 area 0.0.0.0
     ipv6 ospf6 network point-to-point
    !
    !
    router ospf6
     ospf6 router-id 10.0.0.2
     timers lsa min-arrival 100
     timers throttle spf 10 50 500
  
  
    exit
  
    !
    do write

TASK [Deploy ospf configuration] ***********************************************
skipping: [x1]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/srlinux.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for r1, r2, rr2

TASK [Generate JSON-RPC YAML configuration] ************************************
ok: [dut]

TASK [Update SRL ospf node configuration (template=/home/pipi/net101/tools/netsim/ansible/templates/ospf/srlinux.j2)] ***
changed: [dut]

TASK [debug] *******************************************************************
skipping: [dut]

TASK [template] ****************************************************************
changed: [r2]
changed: [r1]
changed: [rr2]

TASK [set_fact] ****************************************************************
ok: [r1]
ok: [r2]
ok: [rr2]

TASK [run /tmp/config.sh to deploy ospf config from /home/pipi/net101/tools/netsim/ansible/templates/ospf/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [rr2]

TASK [run vtysh to import ospf config from /home/pipi/net101/tools/netsim/ansible/templates/ospf/frr.j2] ***
changed: [r1]
changed: [r2]
changed: [rr2]

PLAY [Deploy custom deployment templates] **************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
dut                        : ok=31   changed=3    unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
r1                         : ok=36   changed=7    unreachable=0    failed=0    skipped=11   rescued=0    ignored=0   
r2                         : ok=35   changed=6    unreachable=0    failed=0    skipped=11   rescued=0    ignored=0   
rr2                        : ok=35   changed=6    unreachable=0    failed=0    skipped=11   rescued=0    ignored=0   
x1                         : ok=28   changed=4    unreachable=0    failed=0    skipped=14   rescued=0    ignored=0   



Use this topology to test the IBGP RR implementation (rr-clients and
cluster-id) and next-hop handling (change next hop on EBGP but not on
reflected route) on IPv6 IBGP sessions.

