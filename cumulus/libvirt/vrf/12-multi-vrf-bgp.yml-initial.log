[WARNING]: Could not match supplied host pattern, ignoring: unprovisioned

PLAY [Deploy initial device configuration] *************************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Find device readiness script] ********************************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Wait for device to become ready] *****************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Normalize config on bridge-like devices] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4

TASK [Figure out whether to deploy the module normalize on current device] *****
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Find configuration template for normalize] *******************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Find configuration deployment deploy_script for normalize] ***************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Deploy normalize configuration] ******************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4

TASK [Figure out whether to deploy the module initial on current device] *******
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Find configuration template for initial] *********************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [r1] => 
  msg: |-
    initial configuration for r1
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r1
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.11/32
    !
    interface eth1
     no shutdown
     description r1 -> dut [external]
     ip address 10.1.0.2/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r2] => 
  msg: |-
    initial configuration for r2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r2
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.12/32
    !
    interface eth1
     no shutdown
     description r2 -> dut [external]
     ip address 10.1.0.6/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [dut] => 
  msg: |-
    initial configuration for dut
    =========================================
    #!/bin/bash
    #
    set -e
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "INIT: setting hostname"
    hostname dut
    #
    #
    # Build hosts file
    #
    #
    cat <<SCRIPT >/tmp/hosts
    #
    # Created by netlab initial
    #
    10.0.0.1 dut
    10.1.0.1 swp1.red.dut
    10.1.0.5 swp2.red.dut
    10.1.0.9 swp3.blue.dut
    10.1.0.13 swp4.blue.dut
    10.0.0.11 r1
    10.1.0.2 eth1.r1
    10.0.0.12 r2
    10.1.0.6 eth1.r2
    10.0.0.23 r3
    10.1.0.10 eth1.r3
    10.0.0.24 r4
    10.1.0.14 eth1.r4
    SCRIPT
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts >>/etc/hosts
    #
    # Disable ZTP
    #
    ztp --disable
    #
    #
  
    echo "INIT: Configuring system wide default MTU policy"
    cat > /etc/network/ifupdown2/policy.d/mtu.json <<CONFIG
    { "address": { "defaults": { "mtu": "1500" } } }
    CONFIG
    #
    echo "INIT: creating loopback interface"
    #
    # Create loopback interface entry
    #
    cat >/etc/network/interfaces.d/10-loopback.intf <<CONFIG
    auto lo
    iface lo inet loopback
      address 10.0.0.1/32
  
    CONFIG
    #
    until ifreload -a; do
      sleep 1
    done
    #
    echo "INIT: creating other interface"
    cat >/etc/network/interfaces.d/11-physical.intf <<CONFIG
    auto swp1
  
    iface swp1 inet static
      address 10.1.0.1/30
    auto swp2
  
    iface swp2 inet static
      address 10.1.0.5/30
    auto swp3
  
    iface swp3 inet static
      address 10.1.0.9/30
    auto swp4
  
    iface swp4 inet static
      address 10.1.0.13/30
    CONFIG
    #
    echo "INIT: executing ifreload"
    until ifreload -a; do
      sleep 1
    done
    #
    # For whatever crazy reason, I had to enable IPv6 in containers
    #
    sysctl -qw net.ipv6.conf.swp1.disable_ipv6=0
    sysctl -qw net.ipv6.conf.swp2.disable_ipv6=0
    sysctl -qw net.ipv6.conf.swp3.disable_ipv6=0
    sysctl -qw net.ipv6.conf.swp4.disable_ipv6=0
    #
    # Enable FRR modules for ['bgp', 'vrf']
    #
    #
    # Enable FRR daemons
    #
    echo "bgpd=yes" >>/etc/frr/daemons
    echo "bgpd=yes" >>/etc/frr/daemons
  
    systemctl enable frr.service
    systemctl start frr.service
    systemctl reload frr.service
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    !
    interface swp1
    ! no shutdown
     description dut -> r1 [external]
    !
    interface swp2
    ! no shutdown
     description dut -> r2 [external]
    !
    interface swp3
    ! no shutdown
     description dut -> r3 [external]
    !
    interface swp4
    ! no shutdown
     description dut -> r4 [external]
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    #
    # Enable LLDP
    #
    echo "INIT: enabling LLDP"
    cat <<CONFIG >/etc/lldpd.d/system.conf
    configure lldp tx-interval 30
    configure lldp tx-hold 3
    configure system interface pattern *,!eth0,swp*
    CONFIG
    service lldpd restart
ok: [r3] => 
  msg: |-
    initial configuration for r3
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r3
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.23/32
    !
    interface eth1
     no shutdown
     description r3 -> dut [external]
     ip address 10.1.0.10/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r4] => 
  msg: |-
    initial configuration for r4
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r4
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.24/32
    !
    interface eth1
     no shutdown
     description r4 -> dut [external]
     ip address 10.1.0.14/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0

TASK [Find configuration deployment deploy_script for initial] *****************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/cumulus.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/initial-clab.yml for r1, r2, r3, r4

TASK [Render device configuration from /home/pipi/net101/tools/netsim/ansible/templates/initial/cumulus.j2] ***
ok: [dut]

TASK [Create local temporary file] *********************************************
changed: [dut -> localhost]

TASK [Create initial config script in local temporary file] ********************
changed: [dut -> localhost]

TASK [Execute local config script on Cumulus node] *****************************
changed: [dut]

TASK [Remove temporary file /tmp/ansible.dut.wrybnol1temp] *********************
changed: [dut -> localhost]

TASK [Attempt to load VRF kernel module] ***************************************
changed: [r1 -> localhost]

TASK [Disable FRR management VRF when modprobe fails] **************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for r1, r2, r3, r4

TASK [template] ****************************************************************
changed: [r4]
changed: [r1]
changed: [r3]
changed: [r2]

TASK [set_fact] ****************************************************************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [run /tmp/config.sh to deploy initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
changed: [r2]
changed: [r1]
changed: [r3]
changed: [r4]

TASK [run vtysh to import initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

PLAY [Deploy module-specific configurations] ***********************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Deploy individual configuration modules] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4 => (item=bgp)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4 => (item=vrf)

TASK [Figure out whether to deploy the module bgp on current device] ***********
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Find configuration template for bgp] *************************************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [dut] => 
  msg: |-
    bgp configuration for dut
    =========================================
    !
    router bgp 65000
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.1
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.1/32
    !
    !
    !
    !
    !
    do write
ok: [r1] => 
  msg: |-
    bgp configuration for r1
    =========================================
    !
    router bgp 65101
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.11
    !
      neighbor 10.1.0.1 remote-as 65000
      neighbor 10.1.0.1 description dut
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.11/32
    !
    !
    !
      neighbor 10.1.0.1 activate
      no neighbor 10.1.0.1 send-community all
      neighbor 10.1.0.1 send-community standard
      neighbor 10.1.0.1 send-community large
    !
    !
    !
    do write
ok: [r2] => 
  msg: |-
    bgp configuration for r2
    =========================================
    !
    router bgp 65102
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.12
    !
      neighbor 10.1.0.5 remote-as 65000
      neighbor 10.1.0.5 description dut
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.12/32
    !
    !
    !
      neighbor 10.1.0.5 activate
      no neighbor 10.1.0.5 send-community all
      neighbor 10.1.0.5 send-community standard
      neighbor 10.1.0.5 send-community large
    !
    !
    !
    do write
ok: [r3] => 
  msg: |-
    bgp configuration for r3
    =========================================
    !
    router bgp 65103
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.23
    !
      neighbor 10.1.0.9 remote-as 65000
      neighbor 10.1.0.9 description dut
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.23/32
    !
    !
    !
      neighbor 10.1.0.9 activate
      no neighbor 10.1.0.9 send-community all
      neighbor 10.1.0.9 send-community standard
      neighbor 10.1.0.9 send-community large
    !
    !
    !
    do write
ok: [r4] => 
  msg: |-
    bgp configuration for r4
    =========================================
    !
    router bgp 65104
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.24
    !
      neighbor 10.1.0.13 remote-as 65000
      neighbor 10.1.0.13 description dut
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.24/32
    !
    !
    !
      neighbor 10.1.0.13 activate
      no neighbor 10.1.0.13 send-community all
      neighbor 10.1.0.13 send-community standard
      neighbor 10.1.0.13 send-community large
    !
    !
    !
    do write

TASK [Find configuration deployment deploy_script for bgp] *********************
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Deploy bgp configuration] ************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/cumulus.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for r1, r2, r3, r4

TASK [Render device configuration from /home/pipi/net101/tools/netsim/ansible/templates/bgp/cumulus.j2] ***
ok: [dut]

TASK [Create local temporary file] *********************************************
changed: [dut -> localhost]

TASK [Create bgp config script in local temporary file] ************************
changed: [dut -> localhost]

TASK [Execute local config script on Cumulus node] *****************************
changed: [dut]

TASK [Remove temporary file /tmp/ansible.dut.zysx7_v0temp] *********************
changed: [dut -> localhost]

TASK [template] ****************************************************************
changed: [r3]
changed: [r1]
changed: [r2]
changed: [r4]

TASK [set_fact] ****************************************************************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [run /tmp/config.sh to deploy bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [run vtysh to import bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
changed: [r1]
changed: [r2]
changed: [r3]
changed: [r4]

TASK [Figure out whether to deploy the module vrf on current device] ***********
ok: [dut]
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [Find configuration template for vrf] *************************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
ok: [dut]
skipping: [r4]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
ok: [dut] => 
  msg: |-
    vrf configuration for dut
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
    cat >/etc/network/interfaces.d/70-vrf.intf <<CONFIG
    auto blue
    iface blue
        vrf-table 1011
    #
    auto red
    iface red
        vrf-table 1010
    #
    auto swp1
    iface swp1
        vrf red
    #
    auto swp2
    iface swp2
        vrf red
    #
    auto swp3
    iface swp3
        vrf blue
    #
    auto swp4
    iface swp4
        vrf blue
    #
    CONFIG
    ifreload -a
    #
    cat >/tmp/vrf_config <<CONFIG
    vrf blue
     exit-vrf
    vrf red
     exit-vrf
    !
    router bgp 65000
    !
    !
    router bgp 65000 vrf blue
     no bgp ebgp-requires-policy
     no bgp default ipv4-unicast
     bgp router-id 10.0.0.1
     neighbor 10.1.0.10 remote-as 65103
     neighbor 10.1.0.10 description r3
     neighbor 10.1.0.14 remote-as 65104
     neighbor 10.1.0.14 description r4
     address-family ipv4 unicast
      redistribute connected
  
      label vpn export auto
      export vpn
      import vpn
      rd vpn export 65000:2
      rt vpn import 65000:2
      rt vpn export 65000:2
      neighbor 10.1.0.10 activate
      neighbor 10.1.0.10 send-community standard
      neighbor 10.1.0.10 send-community large
      neighbor 10.1.0.14 activate
      neighbor 10.1.0.14 send-community standard
      neighbor 10.1.0.14 send-community large
     exit-address-family
    !
    !
    router bgp 65000 vrf red
     no bgp ebgp-requires-policy
     no bgp default ipv4-unicast
     bgp router-id 10.0.0.1
     neighbor 10.1.0.2 remote-as 65101
     neighbor 10.1.0.2 description r1
     neighbor 10.1.0.6 remote-as 65102
     neighbor 10.1.0.6 description r2
     address-family ipv4 unicast
      redistribute connected
  
      label vpn export auto
      export vpn
      import vpn
      rd vpn export 65000:1
      rt vpn import 65000:1
      rt vpn export 65000:1
      neighbor 10.1.0.2 activate
      neighbor 10.1.0.2 send-community standard
      neighbor 10.1.0.2 send-community large
      neighbor 10.1.0.6 activate
      neighbor 10.1.0.6 send-community standard
      neighbor 10.1.0.6 send-community large
     exit-address-family
    !
    !
    do write
    !
    CONFIG
    vtysh -f /tmp/vrf_config
    exit $?

TASK [Find configuration deployment deploy_script for vrf] *********************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
ok: [dut]

TASK [Deploy vrf configuration] ************************************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/cumulus.yml for dut

TASK [Render device configuration from /home/pipi/net101/tools/netsim/ansible/templates/vrf/cumulus.j2] ***
ok: [dut]

TASK [Create local temporary file] *********************************************
changed: [dut -> localhost]

TASK [Create vrf config script in local temporary file] ************************
changed: [dut -> localhost]

TASK [Execute local config script on Cumulus node] *****************************
changed: [dut]

TASK [Remove temporary file /tmp/ansible.dut.3vya3ud7temp] *********************
changed: [dut -> localhost]

PLAY [Deploy custom deployment templates] **************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
dut                        : ok=39   changed=12   unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
r1                         : ok=28   changed=5    unreachable=0    failed=0    skipped=15   rescued=0    ignored=0   
r2                         : ok=27   changed=4    unreachable=0    failed=0    skipped=15   rescued=0    ignored=0   
r3                         : ok=27   changed=4    unreachable=0    failed=0    skipped=15   rescued=0    ignored=0   
r4                         : ok=27   changed=4    unreachable=0    failed=0    skipped=15   rescued=0    ignored=0   



The device under test has two VRFs with two interfaces in each VRF.
Routers are attached to those interfaces and run BGP with device under test.
Assuming the multi-vrf test case succeeded, this one adds BGP routing with
CE routers.

* r1 and r2 should be able to ping each other
* r3 and r4 should be able to ping each other
* r1 should not be able to reach r3

