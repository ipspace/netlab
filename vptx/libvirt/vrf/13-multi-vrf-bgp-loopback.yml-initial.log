[WARNING]: Could not match supplied host pattern, ignoring: unprovisioned

PLAY [Deploy initial device configuration] *************************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [r1]
ok: [r2]
ok: [dut]
ok: [r3]
ok: [r4]

TASK [Find device readiness script] ********************************************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]
ok: [dut]

TASK [Wait for device to become ready] *****************************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/readiness-check/vptx.yml for dut

TASK [Wait for et-0/0/0 to appear] *********************************************
ok: [dut]

TASK [Normalize config on bridge-like devices] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4

TASK [Figure out whether to deploy the module normalize on current device] *****
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]
ok: [dut]

TASK [Find configuration template for normalize] *******************************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [dut]
ok: [r4]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Find configuration deployment deploy_script for normalize] ***************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Deploy normalize configuration] ******************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4

TASK [Figure out whether to deploy the module initial on current device] *******
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]
ok: [dut]

TASK [Find configuration template for initial] *********************************
ok: [r1]
ok: [r2]
ok: [r4]
ok: [r3]
ok: [dut]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [r1] => 
  msg: |-
    initial configuration for r1
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r1
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.2/32
    !
    interface eth1
     no shutdown
     description r1 -> dut [external]
     ip address 10.1.0.2/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r2] => 
  msg: |-
    initial configuration for r2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r2
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.3/32
    !
    interface eth1
     no shutdown
     description r2 -> dut [external]
     ip address 10.1.0.6/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r3] => 
  msg: |-
    initial configuration for r3
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r3
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.4/32
    !
    interface eth1
     no shutdown
     description r3 -> dut [external]
     ip address 10.1.0.10/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [r4] => 
  msg: |-
    initial configuration for r4
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)# "
    echo
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks, stub and lag/bond devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    ip link set dev eth1 mtu 1500
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
  
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname r4
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.5/32
    !
    interface eth1
     no shutdown
     description r4 -> dut [external]
     ip address 10.1.0.14/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [dut] => 
  msg: |-
    initial configuration for dut
    =========================================
    system {
      host-name dut;
      static-host-mapping {
        r1 inet 10.0.0.2;
        r2 inet 10.0.0.3;
        r3 inet 10.0.0.4;
        r4 inet 10.0.0.5;
      }
    }
  
  
  
  
  
  
  
  
    policy-options {
      community tg_65000_2 members target:65000:2;
      community tg_65000_1 members target:65000:1;
    }
  
  
  
    policy-options {
      policy-statement vrf-blue-export {
        term 1 {
          then {
            community add tg_65000_2;
            accept;
          }
        }
      }
  
  
  
      policy-statement vrf-blue-import {
        term 1 {
          from community [ tg_65000_2 ];
          then accept;
        }
        term default {
          then reject;
        }
      }
      policy-statement vrf-red-export {
        term 1 {
          then {
            community add tg_65000_1;
            accept;
          }
        }
      }
  
  
  
      policy-statement vrf-red-import {
        term 1 {
          from community [ tg_65000_1 ];
          then accept;
        }
        term default {
          then reject;
        }
      }
    }
  
    routing-instances {
  
      blue {
        instance-type vrf;
        route-distinguisher 65000:2;
  
        vrf-import vrf-blue-import;
        vrf-export vrf-blue-export;
  
        routing-options {
          auto-export;
        }
  
        interface et-0/0/2.0;
        interface et-0/0/3.0;
        interface lo0.2;
  
      }
  
  
      red {
        instance-type vrf;
        route-distinguisher 65000:1;
  
        vrf-import vrf-red-import;
        vrf-export vrf-red-export;
  
        routing-options {
          auto-export;
        }
  
        interface et-0/0/0.0;
        interface et-0/0/1.0;
        interface lo0.1;
  
      }
  
    }
    interfaces {
  
      lo0.0 {
  
          family inet {
            address 10.0.0.1/32;
          }
  
      }
      et-0/0/0.0 {
        description "dut -> r1 [external]";
  
          family inet {
            address 10.1.0.1/30;
          }
  
      }
      et-0/0/1.0 {
        description "dut -> r2 [external]";
  
          family inet {
            address 10.1.0.5/30;
          }
  
      }
      et-0/0/2.0 {
        description "dut -> r3 [external]";
  
          family inet {
            address 10.1.0.9/30;
          }
  
      }
      et-0/0/3.0 {
        description "dut -> r4 [external]";
  
          family inet {
            address 10.1.0.13/30;
          }
  
      }
      lo0.1 {
        description "VRF Loopback red";
  
          family inet {
            address 10.0.0.42/32;
          }
  
      }
      lo0.2 {
        description "VRF Loopback blue";
  
          family inet {
            address 10.0.0.43/32;
          }
  
      }
    }
    protocols {
      lldp {
        interface re0:mgmt-0 {
          disable;
        }
        interface all;
      }
    }

TASK [Find configuration deployment deploy_script for initial] *****************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [dut]
ok: [r4]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/junos.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/initial-clab.yml for r1, r2, r3, r4

TASK [junos_config: deploying initial from /home/pipi/net101/tools/netsim/ansible/templates/initial/junos.j2] ***
changed: [dut]

TASK [Attempt to load VRF kernel module] ***************************************
changed: [r1 -> localhost]

TASK [Disable FRR management VRF when modprobe fails] **************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for r1, r2, r3, r4

TASK [template] ****************************************************************
changed: [r2]
changed: [r4]
changed: [r1]
changed: [r3]

TASK [set_fact] ****************************************************************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [run /tmp/config.sh to deploy initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
changed: [r1]
changed: [r2]
changed: [r3]
changed: [r4]

TASK [run vtysh to import initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

PLAY [Deploy module-specific configurations] ***********************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]
ok: [dut]

TASK [Deploy individual configuration modules] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4 => (item=bgp)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, r1, r2, r3, r4 => (item=vrf)

TASK [Figure out whether to deploy the module bgp on current device] ***********
ok: [r1]
ok: [r2]
ok: [r4]
ok: [r3]
ok: [dut]

TASK [Find configuration template for bgp] *************************************
ok: [r1]
ok: [r2]
ok: [dut]
ok: [r3]
ok: [r4]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [r1] => 
  msg: |-
    bgp configuration for r1
    =========================================
    !
    router bgp 65101
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.2
    !
      neighbor 10.1.0.1 remote-as 65000
      neighbor 10.1.0.1 description dut
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.2/32
    !
    !
    !
      neighbor 10.1.0.1 activate
      no neighbor 10.1.0.1 send-community all
      neighbor 10.1.0.1 send-community standard
      neighbor 10.1.0.1 send-community large
    !
    !
    !
    do write
ok: [dut] => 
  msg: |-
    bgp configuration for dut
    =========================================
    routing-options {
      autonomous-system 65000;
      router-id 10.0.0.1
    }
    policy-options {
      delete: policy-statement ibgp-export;
      delete: policy-statement ebgp-export;
    }
    policy-options {
      policy-statement ibgp-export {
        term advertise {
          from {
            protocol direct;
            interface [
               lo0.0  ];
          }
          then accept;
        }
        term next-hop-self {
          from {
            route-type external;
          }
          then {
            next-hop self;
          }
        }
      }
      policy-statement ebgp-export {
        term advertise {
          from {
            protocol direct;
            interface [ lo0.0 ];
          }
          then accept;
        }
      }
    }
    protocols {
      delete: bgp;
    }
    protocols {
      bgp {
        group ibgp-peers-ipv4 {
          type internal;
          export ibgp-export;
          advertise-inactive;
          local-address 10.0.0.1;
        }
        group ebgp-peers {
          export ebgp-export;
          advertise-inactive;
        }
      }
    }
ok: [r2] => 
  msg: |-
    bgp configuration for r2
    =========================================
    !
    router bgp 65102
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.3
    !
      neighbor 10.1.0.5 remote-as 65000
      neighbor 10.1.0.5 description dut
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.3/32
    !
    !
    !
      neighbor 10.1.0.5 activate
      no neighbor 10.1.0.5 send-community all
      neighbor 10.1.0.5 send-community standard
      neighbor 10.1.0.5 send-community large
    !
    !
    !
    do write
ok: [r3] => 
  msg: |-
    bgp configuration for r3
    =========================================
    !
    router bgp 65103
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.4
    !
      neighbor 10.1.0.9 remote-as 65000
      neighbor 10.1.0.9 description dut
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.4/32
    !
    !
    !
      neighbor 10.1.0.9 activate
      no neighbor 10.1.0.9 send-community all
      neighbor 10.1.0.9 send-community standard
      neighbor 10.1.0.9 send-community large
    !
    !
    !
    do write
ok: [r4] => 
  msg: |-
    bgp configuration for r4
    =========================================
    !
    router bgp 65104
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.5
    !
      neighbor 10.1.0.13 remote-as 65000
      neighbor 10.1.0.13 description dut
    !
     address-family ipv4 unicast
    !
  
    !
      network 10.0.0.5/32
    !
    !
    !
      neighbor 10.1.0.13 activate
      no neighbor 10.1.0.13 send-community all
      neighbor 10.1.0.13 send-community standard
      neighbor 10.1.0.13 send-community large
    !
    !
    !
    do write

TASK [Find configuration deployment deploy_script for bgp] *********************
ok: [r1]
ok: [r4]
ok: [dut]
ok: [r2]
ok: [r3]

TASK [Deploy bgp configuration] ************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/junos.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for r1, r2, r3, r4

TASK [junos_config: deploying bgp from /home/pipi/net101/tools/netsim/ansible/templates/bgp/junos.j2] ***
[WARNING]:  statement not found
changed: [dut]

TASK [template] ****************************************************************
changed: [r2]
changed: [r3]
changed: [r1]
changed: [r4]

TASK [set_fact] ****************************************************************
ok: [r1]
ok: [r2]
ok: [r3]
ok: [r4]

TASK [run /tmp/config.sh to deploy bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [run vtysh to import bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
changed: [r1]
changed: [r2]
changed: [r3]
changed: [r4]

TASK [Figure out whether to deploy the module vrf on current device] ***********
ok: [r1]
ok: [r2]
ok: [r3]
ok: [dut]
ok: [r4]

TASK [Find configuration template for vrf] *************************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
ok: [dut]

TASK [fail] ********************************************************************
skipping: [dut]
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
ok: [dut] => 
  msg: |-
    vrf configuration for dut
    =========================================
  
  
    policy-options {
  
      policy-statement vrf-blue-ibgp-export {
        term redis_direct {
          from {
            protocol direct;
          }
          then accept;
        }
        term redis_ospf {
          from {
            protocol ospf;
          }
          then accept;
        }
        term redis_ospf3 {
          from {
            protocol ospf3;
          }
          then accept;
        }
        term next-hop-self {
          from {
            route-type external;
          }
          then {
            next-hop self;
          }
        }
      }
  
      policy-statement vrf-blue-ebgp-export {
        term redis_direct {
          from {
            protocol direct;
          }
          then accept;
        }
        term redis_ospf {
          from {
            protocol ospf;
          }
          then accept;
        }
        term redis_ospf3 {
          from {
            protocol ospf3;
          }
          then accept;
        }
      }
  
  
      policy-statement vrf-red-ibgp-export {
        term redis_direct {
          from {
            protocol direct;
          }
          then accept;
        }
        term redis_ospf {
          from {
            protocol ospf;
          }
          then accept;
        }
        term redis_ospf3 {
          from {
            protocol ospf3;
          }
          then accept;
        }
        term next-hop-self {
          from {
            route-type external;
          }
          then {
            next-hop self;
          }
        }
      }
  
      policy-statement vrf-red-ebgp-export {
        term redis_direct {
          from {
            protocol direct;
          }
          then accept;
        }
        term redis_ospf {
          from {
            protocol ospf;
          }
          then accept;
        }
        term redis_ospf3 {
          from {
            protocol ospf3;
          }
          then accept;
        }
      }
  
    }
  
  
    routing-instances {
  
      blue {
        routing-options {
          autonomous-system 65000;
          router-id 10.0.0.1
        }
  
        protocols {
          bgp {
            group ibgp-peers-ipv4 {
              type internal;
              export vrf-blue-ibgp-export;
              advertise-inactive;
              local-address 10.0.0.43;
            }
  
            group ebgp-peers {
              export vrf-blue-ebgp-export;
              advertise-inactive;
              neighbor 10.1.0.10 {
                peer-as 65103;
                description r3;
              }
              neighbor 10.1.0.14 {
                peer-as 65104;
                description r4;
              }
            }
          }
        }
      }
  
  
      red {
        routing-options {
          autonomous-system 65000;
          router-id 10.0.0.1
        }
  
        protocols {
          bgp {
            group ibgp-peers-ipv4 {
              type internal;
              export vrf-red-ibgp-export;
              advertise-inactive;
              local-address 10.0.0.42;
            }
  
            group ebgp-peers {
              export vrf-red-ebgp-export;
              advertise-inactive;
              neighbor 10.1.0.2 {
                peer-as 65101;
                description r1;
              }
              neighbor 10.1.0.6 {
                peer-as 65102;
                description r2;
              }
            }
          }
        }
      }
  
    }

TASK [Find configuration deployment deploy_script for vrf] *********************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
ok: [dut]

TASK [Deploy vrf configuration] ************************************************
skipping: [r1]
skipping: [r2]
skipping: [r3]
skipping: [r4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/junos.yml for dut

TASK [junos_config: deploying vrf from /home/pipi/net101/tools/netsim/ansible/templates/vrf/junos.j2] ***
changed: [dut]

PLAY [Deploy custom deployment templates] **************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
dut                        : ok=29   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
r1                         : ok=28   changed=5    unreachable=0    failed=0    skipped=15   rescued=0    ignored=0   
r2                         : ok=27   changed=4    unreachable=0    failed=0    skipped=15   rescued=0    ignored=0   
r3                         : ok=27   changed=4    unreachable=0    failed=0    skipped=15   rescued=0    ignored=0   
r4                         : ok=27   changed=4    unreachable=0    failed=0    skipped=15   rescued=0    ignored=0   



The device under test has two VRFs with two interfaces in each VRF.
Routers are attached to those interfaces and run BGP with device under test.
Assuming the multi-vrf BGP test case succeeded, this one adds VRF loopback
interfaces advertised into BGP with network statements.

* r1 and r2 should be able to ping each other and rtr VRF loopback
* r3 and r4 should be able to ping each other and rtr VRF loopback
* r1 should not be able to reach r3

