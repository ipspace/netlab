Bringing machine 'dut' up with 'libvirt' provider...
Bringing machine 'pe2' up with 'libvirt' provider...
==> dut: Checking if box 'cisco/cat8000v' version '17.13.01' is up to date...
==> pe2: Checking if box 'arista/veos' version '4.31.2F' is up to date...
[fog][WARNING] Unrecognized arguments: libvirt_ip_command
==> pe2: There was a problem while downloading the metadata for your box
==> pe2: to check for updates. This is not an error, since it is usually due
==> pe2: to temporary network problems. This is just a warning. The problem
==> pe2: encountered was:
==> pe2: 
==> pe2: Couldn't open file /home/pipi/vagrant/boxes/AX/box.json
==> pe2: 
==> pe2: If you want to check for box updates, verify your network connection
==> pe2: is valid and try again.
[fog][WARNING] Unrecognized arguments: libvirt_ip_command
==> dut: Creating image (snapshot of base box volume).
==> pe2: Creating image (snapshot of base box volume).
==> dut: Creating domain with the following settings...
==> pe2: Creating domain with the following settings...
==> dut:  -- Name:              ml_30_dut
==> dut:  -- Description:       Source: /work/netlab_cicd/cisco/Vagrantfile
==> pe2:  -- Name:              ml_30_pe2
==> dut:  -- Domain type:       kvm
==> dut:  -- Cpus:              2
==> pe2:  -- Description:       Source: /work/netlab_cicd/cisco/Vagrantfile
==> dut:  -- Feature:           acpi
==> pe2:  -- Domain type:       kvm
==> dut:  -- Feature:           apic
==> pe2:  -- Cpus:              2
==> dut:  -- Feature:           pae
==> pe2:  -- Feature:           acpi
==> dut:  -- Clock offset:      utc
==> pe2:  -- Feature:           apic
==> dut:  -- Memory:            4096M
==> pe2:  -- Feature:           pae
==> dut:  -- Management MAC:    08:4f:a9:05:00:00
==> pe2:  -- Clock offset:      utc
==> dut:  -- Base box:          cisco/cat8000v
==> pe2:  -- Memory:            2048M
==> dut:  -- Storage pool:      default
==> pe2:  -- Management MAC:    08:4f:a9:06:00:00
==> dut:  -- Image(vda):        /var/lib/libvirt/images/ml_30_dut.img, virtio, 8G
==> dut:  -- Disk driver opts:  cache='default'
==> pe2:  -- Base box:          arista/veos
==> dut:  -- Graphics Type:     vnc
==> dut:  -- Video Type:        cirrus
==> pe2:  -- Storage pool:      default
==> dut:  -- Video VRAM:        16384
==> dut:  -- Video 3D accel:    false
==> pe2:  -- Image(vda):        /var/lib/libvirt/images/ml_30_pe2.img, ide, 5G
==> dut:  -- Keymap:            en-us
==> pe2:  -- Disk driver opts:  cache='default'
==> dut:  -- TPM Backend:       passthrough
==> pe2:  -- Graphics Type:     vnc
==> dut:  -- INPUT:             type=mouse, bus=ps2
==> pe2:  -- Video Type:        cirrus
==> pe2:  -- Video VRAM:        16384
==> pe2:  -- Video 3D accel:    false
==> pe2:  -- Keymap:            en-us
==> pe2:  -- TPM Backend:       passthrough
==> pe2:  -- INPUT:             type=mouse, bus=ps2
==> dut: Creating shared folders metadata...
==> pe2: Creating shared folders metadata...
==> dut: Starting domain.
==> pe2: Starting domain.
==> dut: Domain launching with graphics connection settings...
==> pe2: Domain launching with graphics connection settings...
==> dut:  -- Graphics Port:      5900
==> pe2:  -- Graphics Port:      5901
==> dut:  -- Graphics IP:        127.0.0.1
==> pe2:  -- Graphics IP:        127.0.0.1
==> dut:  -- Graphics Password:  Not defined
==> pe2:  -- Graphics Password:  Not defined
==> dut:  -- Graphics Websocket: 5700
==> pe2:  -- Graphics Websocket: 5701
==> dut: Waiting for domain to get an IP address...
==> pe2: Waiting for domain to get an IP address...
==> pe2: Waiting for machine to boot. This may take a few minutes...
    pe2: SSH address: 192.168.30.106:22
    pe2: SSH username: vagrant
    pe2: SSH auth method: private key
==> pe2: Machine booted and ready!
==> dut: Waiting for machine to boot. This may take a few minutes...
    dut: SSH address: 192.168.30.105:22
    dut: SSH username: vagrant
    dut: SSH auth method: private key
==> dut: Machine booted and ready!
Using transformed lab topology from snapshot file netlab.snapshot.yml
Checking virtualization provider installation
OK: libvirt installed and working correctly
OK: clab installed and working correctly
Starting libvirt nodes
creating libvirt management network nl_mgmt_30
provider libvirt: executing vagrant up --provider libvirt
Starting clab nodes
Recreating clab-augment.yml configuration file for clab provider
11:36:18 INFO Containerlab started version=0.68.0
11:36:18 INFO Parsing & checking topology file=clab-augment.yml
11:36:18 INFO Removing directory path=/work/netlab_cicd/cisco/clab-ml_30
11:36:18 INFO Creating docker network name=nl_mgmt_30 IPv4 subnet=192.168.30.0/24 IPv6 subnet="" MTU=0
11:36:18 INFO Creating lab directory path=/work/netlab_cicd/cisco/clab-ml_30
11:36:18 INFO Creating container name=h1
11:36:18 INFO Creating container name=p1
11:36:18 INFO Creating container name=h3
11:36:18 INFO Creating container name=p2
11:36:18 INFO Creating container name=h2
11:36:18 INFO Creating container name=h4
11:36:19 INFO Created link: h2:eth1 â–ªâ”„â”„â–ª virbr6:ml_30_2_1
11:36:19 INFO Created link: h3:eth1 â–ªâ”„â”„â–ª virbr4:ml_30_3_1
11:36:19 INFO Created link: p1:eth1 â–ªâ”„â”„â–ª virbr2:ml_30_7_1
11:36:19 INFO Created link: h1:eth1 â–ªâ”„â”„â–ª virbr3:ml_30_1_1
11:36:19 INFO Created link: p1:eth2 â–ªâ”„â”„â–ª p2:eth1
11:36:20 INFO Created link: h4:eth1 â–ªâ”„â”„â–ª virbr7:ml_30_4_1
11:36:20 INFO Created link: p2:eth2 â–ªâ”„â”„â–ª virbr5:ml_30_8_2
11:36:20 INFO Adding host entries path=/etc/hosts
11:36:20 INFO Adding SSH config for nodes path=/etc/ssh/ssh_config.d/clab-ml_30.conf
[1mâ•­[0m[1mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[1mâ”¬[0m[1mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[1mâ”¬[0m[1mâ”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[1mâ”¬[0m[1mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[1mâ•®[0m
[1mâ”‚[0m[1m      Name     [0m[1mâ”‚[0m[1m          Kind/Image          [0m[1mâ”‚[0m[1m  State  [0m[1mâ”‚[0m[1m IPv4/6 Address [0m[1mâ”‚[0m
[1mâ”œ[0m[1mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[1mâ”¼[0m[1mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[1mâ”¼[0m[1mâ”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[1mâ”¼[0m[1mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[1mâ”¤[0m
â”‚ clab-ml_30-h1 â”‚ linux                        â”‚ running â”‚ 192.168.30.101 â”‚
â”‚               â”‚ python:3.13-alpine           â”‚         â”‚ N/A            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ clab-ml_30-h2 â”‚ linux                        â”‚ running â”‚ 192.168.30.102 â”‚
â”‚               â”‚ python:3.13-alpine           â”‚         â”‚ N/A            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ clab-ml_30-h3 â”‚ linux                        â”‚ running â”‚ 192.168.30.103 â”‚
â”‚               â”‚ python:3.13-alpine           â”‚         â”‚ N/A            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ clab-ml_30-h4 â”‚ linux                        â”‚ running â”‚ 192.168.30.104 â”‚
â”‚               â”‚ python:3.13-alpine           â”‚         â”‚ N/A            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ clab-ml_30-p1 â”‚ linux                        â”‚ running â”‚ 192.168.30.107 â”‚
â”‚               â”‚ quay.io/frrouting/frr:10.3.1 â”‚         â”‚ N/A            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ clab-ml_30-p2 â”‚ linux                        â”‚ running â”‚ 192.168.30.108 â”‚
â”‚               â”‚ quay.io/frrouting/frr:10.3.1 â”‚         â”‚ N/A            â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Createdprovider configuration file: clab-augment.yml
Mapped clab_files/h1/hosts to h1:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
Mapped clab_files/h2/hosts to h2:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
Mapped clab_files/h3/hosts to h3:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
Mapped clab_files/h4/hosts to h4:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
Mapped clab_files/p1/daemons to p1:/etc/frr/daemons (from templates/provider/clab/frr/daemons.j2)
Mapped clab_files/p1/hosts to p1:/etc/hosts (from templates/provider/clab/frr/hosts.j2)
Mapped clab_files/p2/daemons to p2:/etc/frr/daemons (from templates/provider/clab/frr/daemons.j2)
Mapped clab_files/p2/hosts to p2:/etc/hosts (from templates/provider/clab/frr/hosts.j2)
Loading Linux kernel modules mpls-router,mpls-iptunnel required by containers using mpls module
provider clab: executing sudo -E containerlab deploy --reconfigure -t clab-augment.yml

Initial configuration skipped, run 'netlab initial' to configure the devices
