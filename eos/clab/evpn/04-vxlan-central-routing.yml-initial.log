[WARNING]: Could not match supplied host pattern, ignoring: unprovisioned

PLAY [Deploy initial device configuration] *************************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [l2]
ok: [h1]
ok: [h2]
ok: [h4]
ok: [h3]
ok: [l1]
ok: [spine]

TASK [Find device readiness script] ********************************************
ok: [l2]
ok: [h1]
ok: [h2]
ok: [l1]
ok: [h4]
ok: [h3]
ok: [spine]

TASK [Wait for device to become ready] *****************************************
skipping: [l2]
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/readiness-check/eos-clab.yml for l1, spine

TASK [Wait for cEOS SSH daemon to start] ***************************************
ok: [spine]
ok: [l1]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine, h1, h2, h3, h4

TASK [Figure out whether to deploy the module initial on current device] *******
ok: [l2]
ok: [h1]
ok: [h3]
ok: [h2]
ok: [l1]
ok: [h4]
ok: [spine]

TASK [Find configuration template for initial] *********************************
ok: [l2]
ok: [h2]
ok: [h1]
ok: [h4]
ok: [h3]
ok: [l1]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l2] => 
  msg: |-
    initial configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "# Created by netlab initial" >>/tmp/hosts
    echo "172.16.0.1 h1" >>/tmp/hosts
    echo "172.16.0.2 h2" >>/tmp/hosts
    echo "172.16.1.3 h3" >>/tmp/hosts
    echo "172.16.1.4 h4" >>/tmp/hosts
    echo "10.0.0.5 10.1.0.1 l1" >>/tmp/hosts
    echo "10.0.0.6 10.1.0.5 l2" >>/tmp/hosts
    echo "10.0.0.7 10.1.0.2 10.1.0.6 spine" >>/tmp/hosts
    echo "172.16.0.7 172.16.1.7 spine-customer" >>/tmp/hosts
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts|sort >>/etc/hosts
  
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    sysctl -qw net.ipv6.conf.eth2.disable_ipv6=1
    sysctl -qw net.ipv6.conf.eth3.disable_ipv6=1
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1600
    ip link set eth2 mtu 1500
    ip link set eth3 mtu 1500
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname l2
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.6/32
    !
    interface eth1
     no shutdown
     description l2 -> spine
     ip address 10.1.0.5/30
    !
    interface eth2
     no shutdown
     ! no ip address
    !
    interface eth3
     no shutdown
     ! no ip address
    !
    interface vlan1000
     no shutdown
     description VLAN red (1000) -> [h1,l1,h2,spine] [external]
     ! no ip address
    !
    interface vlan1001
     no shutdown
     description VLAN blue (1001) -> [h3,l1,h4,spine] [external]
     ! no ip address
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [h1] => 
  msg: |-
    initial configuration for h1
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.0.1/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.0.1/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    # lan prefix: 172.16.0.0/16 local subnet: 172.16.0.0/24
    set +e
    ip route del 172.16.0.0/16 2>/dev/null
    set -e
    ip route add 172.16.0.0/16 via 172.16.0.7
    # loopback prefix: 10.0.0.0/24 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.0.0.0/24 2>/dev/null
    set -e
    ip route add 10.0.0.0/24 via 172.16.0.7
    # mgmt prefix: 192.168.17.0/24 local subnet: 172.16.0.0/24
    # p2p prefix: 10.1.0.0/16 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.1.0.0/16 2>/dev/null
    set -e
    ip route add 10.1.0.0/16 via 172.16.0.7
    # router_id prefix: 10.0.0.0/24 local subnet: 172.16.0.0/24
    # vrf_loopback prefix: 10.2.0.0/24 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.2.0.0/24 2>/dev/null
    set -e
    ip route add 10.2.0.0/24 via 172.16.0.7
    #
    # Print the final routing table
    ip route
ok: [h4] => 
  msg: |-
    initial configuration for h4
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.1.4/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.1.4/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    # lan prefix: 172.16.0.0/16 local subnet: 172.16.1.0/24
    set +e
    ip route del 172.16.0.0/16 2>/dev/null
    set -e
    ip route add 172.16.0.0/16 via 172.16.1.7
    # loopback prefix: 10.0.0.0/24 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.0.0.0/24 2>/dev/null
    set -e
    ip route add 10.0.0.0/24 via 172.16.1.7
    # mgmt prefix: 192.168.17.0/24 local subnet: 172.16.1.0/24
    # p2p prefix: 10.1.0.0/16 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.1.0.0/16 2>/dev/null
    set -e
    ip route add 10.1.0.0/16 via 172.16.1.7
    # router_id prefix: 10.0.0.0/24 local subnet: 172.16.1.0/24
    # vrf_loopback prefix: 10.2.0.0/24 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.2.0.0/24 2>/dev/null
    set -e
    ip route add 10.2.0.0/24 via 172.16.1.7
    #
    # Print the final routing table
    ip route
ok: [l1] => 
  msg: |-
    initial configuration for l1
    =========================================
    hostname l1
    !
    logging monitor debugging
    !
    lldp run
    ip routing
    !
    vrf instance customer
     rd 65000:1
    !
    !
    ip host h1 172.16.0.1
    ip host h2 172.16.0.2
    ip host h3 172.16.1.3
    ip host h4 172.16.1.4
    ip host l2 10.0.0.6 10.1.0.5
    ip host spine 10.0.0.7 10.1.0.2 10.1.0.6
    ip host spine-customer 172.16.0.7 172.16.1.7
    !
    interface Management0
     no lldp transmit
     no lldp receive
    !
    interface Loopback0
     no shutdown
     ip address 10.0.0.5/32
    !
    interface Ethernet1
     no shutdown
     no switchport
     mtu 1600
     description l1 -> spine
     ip address 10.1.0.1/30
    !
     mac-address 52dc.cafe.0501
    !
    interface Ethernet2
     no shutdown
     no switchport
    !
     mac-address 52dc.cafe.0502
    !
    interface Ethernet3
     no shutdown
     no switchport
    !
     mac-address 52dc.cafe.0503
    !
    interface Vlan1000
     no shutdown
     vrf customer
     description VLAN red (1000) -> [h1,h2,l2,spine] [external]
    !
    interface Vlan1001
     no shutdown
     vrf customer
     description VLAN blue (1001) -> [h3,h4,l2,spine] [external]
    !
ok: [h2] => 
  msg: |-
    initial configuration for h2
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.0.2/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.0.2/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    # lan prefix: 172.16.0.0/16 local subnet: 172.16.0.0/24
    set +e
    ip route del 172.16.0.0/16 2>/dev/null
    set -e
    ip route add 172.16.0.0/16 via 172.16.0.7
    # loopback prefix: 10.0.0.0/24 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.0.0.0/24 2>/dev/null
    set -e
    ip route add 10.0.0.0/24 via 172.16.0.7
    # mgmt prefix: 192.168.17.0/24 local subnet: 172.16.0.0/24
    # p2p prefix: 10.1.0.0/16 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.1.0.0/16 2>/dev/null
    set -e
    ip route add 10.1.0.0/16 via 172.16.0.7
    # router_id prefix: 10.0.0.0/24 local subnet: 172.16.0.0/24
    # vrf_loopback prefix: 10.2.0.0/24 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.2.0.0/24 2>/dev/null
    set -e
    ip route add 10.2.0.0/24 via 172.16.0.7
    #
    # Print the final routing table
    ip route
ok: [h3] => 
  msg: |-
    initial configuration for h3
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.1.3/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.1.3/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    # lan prefix: 172.16.0.0/16 local subnet: 172.16.1.0/24
    set +e
    ip route del 172.16.0.0/16 2>/dev/null
    set -e
    ip route add 172.16.0.0/16 via 172.16.1.7
    # loopback prefix: 10.0.0.0/24 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.0.0.0/24 2>/dev/null
    set -e
    ip route add 10.0.0.0/24 via 172.16.1.7
    # mgmt prefix: 192.168.17.0/24 local subnet: 172.16.1.0/24
    # p2p prefix: 10.1.0.0/16 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.1.0.0/16 2>/dev/null
    set -e
    ip route add 10.1.0.0/16 via 172.16.1.7
    # router_id prefix: 10.0.0.0/24 local subnet: 172.16.1.0/24
    # vrf_loopback prefix: 10.2.0.0/24 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.2.0.0/24 2>/dev/null
    set -e
    ip route add 10.2.0.0/24 via 172.16.1.7
    #
    # Print the final routing table
    ip route
ok: [spine] => 
  msg: |-
    initial configuration for spine
    =========================================
    hostname spine
    !
    logging monitor debugging
    !
    lldp run
    ip routing
    !
    vrf instance customer
     rd 65000:1
    !
    ip routing vrf customer
    !
    !
    ip host h1 172.16.0.1
    ip host h2 172.16.0.2
    ip host h3 172.16.1.3
    ip host h4 172.16.1.4
    ip host l1 10.0.0.5 10.1.0.1
    ip host l2 10.0.0.6 10.1.0.5
    ip host spine-customer 172.16.0.7 172.16.1.7
    !
    interface Management0
     no lldp transmit
     no lldp receive
    !
    interface Loopback0
     no shutdown
     ip address 10.0.0.7/32
    !
    interface Ethernet1
     no shutdown
     no switchport
     mtu 1600
     description spine -> l1
     ip address 10.1.0.2/30
    !
     mac-address 52dc.cafe.0701
    !
    interface Ethernet2
     no shutdown
     no switchport
     mtu 1600
     description spine -> l2
     ip address 10.1.0.6/30
    !
     mac-address 52dc.cafe.0702
    !
    interface Vlan1000
     no shutdown
     vrf customer
     description VLAN red (1000) -> [h1,l1,h2,l2] [external]
     ip address 172.16.0.7/24
    !
    interface Vlan1001
     no shutdown
     vrf customer
     description VLAN blue (1001) -> [h3,l1,h4,l2] [external]
     ip address 172.16.1.7/24
    !

TASK [Find configuration deployment deploy_script for initial] *****************
ok: [l2]
ok: [h1]
ok: [h3]
ok: [h2]
ok: [h4]
ok: [l1]
ok: [spine]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/eos.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/initial-clab.yml for l2
included: /home/pipi/net101/tools/netsim/ansible/tasks/linux/initial-clab.yml for h1, h2, h3, h4

TASK [eos_config: deploying initial from /home/pipi/net101/tools/netsim/ansible/templates/initial/eos.j2] ***
[WARNING]: To ensure idempotency and correct diff the input configuration lines
should be similar to how they appear if present in the running configuration on
device including the indentation
changed: [l1]
changed: [spine]

TASK [Attempt to load VRF kernel module] ***************************************
changed: [l2 -> localhost]

TASK [Disable FRR management VRF when modprobe fails] **************************
skipping: [l2]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for l2

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
changed: [l2]

TASK [run vtysh to import initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
skipping: [l2]

TASK [set_fact] ****************************************************************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]

TASK [Create initial container setup from /home/pipi/net101/tools/netsim/ansible/templates/initial/linux-clab.j2] ***
changed: [h1 -> localhost]
changed: [h2 -> localhost]
changed: [h4 -> localhost]
changed: [h3 -> localhost]

TASK [Initial container configuration via /tmp/config-uDDtbPjM-h1.sh] **********
changed: [h1 -> localhost]
changed: [h3 -> localhost]
changed: [h2 -> localhost]
changed: [h4 -> localhost]

TASK [file] ********************************************************************
changed: [h4 -> localhost]
changed: [h3 -> localhost]
changed: [h2 -> localhost]
changed: [h1 -> localhost]

PLAY [Deploy module-specific configurations] ***********************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Deploy individual configuration modules] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=vlan)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=bgp)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=ospf)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=vrf)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=vxlan)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for l1, l2, spine => (item=evpn)

TASK [Figure out whether to deploy the module vlan on current device] **********
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Find configuration template for vlan] ************************************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l2] => 
  msg: |-
    vlan configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
    if [ ! -e /sys/devices/virtual/net/vlan1000 ]; then
      brctl addbr vlan1000
      ip link set dev vlan1000 up
      ip addr flush dev vlan1000
    fi
    if [ ! -e /sys/devices/virtual/net/vlan1001 ]; then
      brctl addbr vlan1001
      ip link set dev vlan1001 up
      ip addr flush dev vlan1001
    fi
  
    brctl addif vlan1000 eth2
    brctl addif vlan1001 eth3
    exit 0
ok: [l1] => 
  msg: |-
    vlan configuration for l1
    =========================================
    vlan 1001
     name blue
    !
    vlan 1000
     name red
    !
  
    !
    interface Ethernet2
     switchport
     switchport access vlan 1000
    !
    interface Ethernet3
     switchport
     switchport access vlan 1001
    !
    interface Vlan1000
    !
    interface Vlan1001
ok: [spine] => 
  msg: |-
    vlan configuration for spine
    =========================================
    vlan 1001
     name blue
    !
    vlan 1000
     name red
    !
  
    !
    interface Vlan1000
    !
    interface Vlan1001

TASK [Find configuration deployment deploy_script for vlan] ********************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Deploy vlan configuration] ***********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/eos.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [eos_config: deploying vlan from /home/pipi/net101/tools/netsim/ansible/templates/vlan/eos.j2] ***
changed: [spine]
changed: [l1]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy vlan config from /home/pipi/net101/tools/netsim/ansible/templates/vlan/frr.j2] ***
changed: [l2]

TASK [run vtysh to import vlan config from /home/pipi/net101/tools/netsim/ansible/templates/vlan/frr.j2] ***
skipping: [l2]

TASK [Figure out whether to deploy the module bgp on current device] ***********
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Find configuration template for bgp] *************************************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l2] => 
  msg: |-
    bgp configuration for l2
    =========================================
    !
    router bgp 65000
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.6
    !
      neighbor 10.0.0.7 remote-as 65000
      neighbor 10.0.0.7 description spine
      neighbor 10.0.0.7 update-source lo
    !
     address-family ipv4 unicast
    !
      network 10.0.0.6/32
    !
    !
    !
      neighbor 10.0.0.7 activate
      neighbor 10.0.0.7 next-hop-self
      no neighbor 10.0.0.7 send-community all
      neighbor 10.0.0.7 send-community standard
      neighbor 10.0.0.7 send-community large
      neighbor 10.0.0.7 send-community extended
    !
    !
    !
    do write
ok: [l1] => 
  msg: |-
    bgp configuration for l1
    =========================================
    !
    route-map next-hop-self-ipv4 permit 10
       match route-type external
       set ip next-hop peer-address
    !
    route-map next-hop-self-ipv4 permit 20
    !
    !
    router bgp 65000
      bgp advertise-inactive
      bgp log-neighbor-changes
      no bgp default ipv4-unicast
      no bgp default ipv6-unicast
      router-id 10.0.0.5
    !
      neighbor 10.0.0.7 remote-as 65000
      neighbor 10.0.0.7 description spine
      neighbor 10.0.0.7 update-source Loopback0
      neighbor 10.0.0.7 send-community standard extended large
    !
    !
     address-family ipv4
    !
      network 10.0.0.5/32
    !
    !
    !
      neighbor 10.0.0.7 activate
      neighbor 10.0.0.7 route-map next-hop-self-ipv4 out
    !
ok: [spine] => 
  msg: |-
    bgp configuration for spine
    =========================================
    !
    route-map next-hop-self-ipv4 permit 10
       match route-type external
       set ip next-hop peer-address
    !
    route-map next-hop-self-ipv4 permit 20
    !
    !
    router bgp 65000
      bgp advertise-inactive
      bgp log-neighbor-changes
      no bgp default ipv4-unicast
      no bgp default ipv6-unicast
      router-id 10.0.0.7
      bgp cluster-id 10.0.0.7
    !
      neighbor 10.0.0.5 remote-as 65000
      neighbor 10.0.0.5 description l1
      neighbor 10.0.0.5 update-source Loopback0
      neighbor 10.0.0.5 route-reflector-client
      neighbor 10.0.0.5 send-community standard extended large
    !
      neighbor 10.0.0.6 remote-as 65000
      neighbor 10.0.0.6 description l2
      neighbor 10.0.0.6 update-source Loopback0
      neighbor 10.0.0.6 route-reflector-client
      neighbor 10.0.0.6 send-community standard extended large
    !
    !
     address-family ipv4
    !
      network 10.0.0.7/32
    !
    !
    !
      neighbor 10.0.0.5 activate
      neighbor 10.0.0.5 route-map next-hop-self-ipv4 out
      neighbor 10.0.0.6 activate
      neighbor 10.0.0.6 route-map next-hop-self-ipv4 out
    !

TASK [Find configuration deployment deploy_script for bgp] *********************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Deploy bgp configuration] ************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/eos.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [eos_config: deploying bgp from /home/pipi/net101/tools/netsim/ansible/templates/bgp/eos.j2] ***
changed: [l1]
changed: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
skipping: [l2]

TASK [run vtysh to import bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
changed: [l2]

TASK [Figure out whether to deploy the module ospf on current device] **********
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Find configuration template for ospf] ************************************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l2] => 
  msg: |-
    ospf configuration for l2
    =========================================
    !
    ! OSPFv2 FRR configuration
    !
    router ospf
     ospf router-id 10.0.0.6
     timers throttle spf 10 50 500
     timers throttle lsa all 100
     timers lsa min-arrival 100
  
    exit
    !
    interface lo
    !
     ip ospf area 0.0.0.0
    !
    interface eth1
    ! l2 -> spine
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
  
    !
    do write
ok: [l1] => 
  msg: |-
    ospf configuration for l1
    =========================================
    !
    ! OSPFv2 configuration
    !
    router ospf 1
     router-id 10.0.0.5
     interface unnumbered hello mask tx 0.0.0.0
     timers spf delay initial 100 200 500
     timers lsa rx min interval 100
     timers lsa tx delay initial 100 200 500
  
    !
    interface Loopback0
    !
     ip ospf area 0.0.0.0
    !
    interface Ethernet1
    ! l1 -> spine
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
ok: [spine] => 
  msg: |-
    ospf configuration for spine
    =========================================
    !
    ! OSPFv2 configuration
    !
    router ospf 1
     router-id 10.0.0.7
     interface unnumbered hello mask tx 0.0.0.0
     timers spf delay initial 100 200 500
     timers lsa rx min interval 100
     timers lsa tx delay initial 100 200 500
  
    !
    interface Loopback0
    !
     ip ospf area 0.0.0.0
    !
    interface Ethernet1
    ! spine -> l1
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
    interface Ethernet2
    ! spine -> l2
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !

TASK [Find configuration deployment deploy_script for ospf] ********************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Deploy ospf configuration] ***********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/eos.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [eos_config: deploying ospf from /home/pipi/net101/tools/netsim/ansible/templates/ospf/eos.j2] ***
changed: [l1]
changed: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy ospf config from /home/pipi/net101/tools/netsim/ansible/templates/ospf/frr.j2] ***
skipping: [l2]

TASK [run vtysh to import ospf config from /home/pipi/net101/tools/netsim/ansible/templates/ospf/frr.j2] ***
changed: [l2]

TASK [Figure out whether to deploy the module vrf on current device] ***********
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Find configuration template for vrf] *************************************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l2] => 
  msg: |-
    vrf configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
  
    # Create VRF tables
    if [ ! -e /sys/devices/virtual/net/customer ]; then
    ip link add customer type vrf table 100
    fi
    ip link set customer up
  
    # Move interfaces and loopbacks to vrfs
    sysctl -qw net.ipv6.conf.vlan1000.keep_addr_on_down=1
    ip link set vlan1000 master customer
    sysctl -qw net.ipv6.conf.vlan1001.keep_addr_on_down=1
    ip link set vlan1001 master customer
  
    cat >/tmp/vrf_config <<CONFIG
    vrf customer
     exit-vrf
    !
    router bgp 65000
    !
    !
    router bgp 65000 vrf customer
     no bgp ebgp-requires-policy
     no bgp default ipv4-unicast
     bgp router-id 10.0.0.6
    !
    !
    do write
    !
    CONFIG
    vtysh -f /tmp/vrf_config
    exit $?
ok: [l1] => 
  msg: |-
    vrf configuration for l1
    =========================================
    !
    mpls ip
    !
    router bgp 65000
    !
     vrf customer
      router-id 10.0.0.5
      rd 65000:1
ok: [spine] => 
  msg: |-
    vrf configuration for spine
    =========================================
    !
    mpls ip
    !
    router bgp 65000
    !
     vrf customer
      router-id 10.0.0.7
      rd 65000:1
      route-target import vpn-ipv4 65000:1
      route-target export vpn-ipv4 65000:1
    !
      address-family ipv4
        redistribute connected

TASK [Find configuration deployment deploy_script for vrf] *********************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Deploy vrf configuration] ************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/eos.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [eos_config: deploying vrf from /home/pipi/net101/tools/netsim/ansible/templates/vrf/eos.j2] ***
changed: [l1]
changed: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy vrf config from /home/pipi/net101/tools/netsim/ansible/templates/vrf/frr.j2] ***
changed: [l2]

TASK [run vtysh to import vrf config from /home/pipi/net101/tools/netsim/ansible/templates/vrf/frr.j2] ***
skipping: [l2]

TASK [Figure out whether to deploy the module vxlan on current device] *********
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Find configuration template for vxlan] ***********************************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l2] => 
  msg: |-
    vxlan configuration for l2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
  
  
  
    # Determine max MTU used on interfaces, to configure VXLAN interface
  
    # Create L3 VNIs with bridges and add to correct vrf table
  
    # Create VXLAN L2 interface per vni
    ip link add vxlan1000 type vxlan \
      id 1000 \
      dstport 4789 \
      local 10.0.0.6 nolearning
    #
    # Add it to the VLAN bridge (create if needed for l3 vnis); disable STP
    if [ ! -e /sys/devices/virtual/net/vlan1000 ]; then
    brctl addbr vlan1000
    ip link set up dev vlan1000
    fi
    brctl addif vlan1000 vxlan1000
    brctl stp vlan1000 off
    # Do not generate ipv6 link-local address for VXLAN devices
    ip link set mtu 1600 addrgenmode none dev vxlan1000
    # Disable dynamic MAC learning for evpn, see https://docs.frrouting.org/en/latest/evpn.html
    bridge link set dev vxlan1000 learning off
    ip link set up dev vxlan1000
  
    # Create VXLAN L2 interface per vni
    ip link add vxlan1001 type vxlan \
      id 1001 \
      dstport 4789 \
      local 10.0.0.6 nolearning
    #
    # Add it to the VLAN bridge (create if needed for l3 vnis); disable STP
    if [ ! -e /sys/devices/virtual/net/vlan1001 ]; then
    brctl addbr vlan1001
    ip link set up dev vlan1001
    fi
    brctl addif vlan1001 vxlan1001
    brctl stp vlan1001 off
    # Do not generate ipv6 link-local address for VXLAN devices
    ip link set mtu 1600 addrgenmode none dev vxlan1001
    # Disable dynamic MAC learning for evpn, see https://docs.frrouting.org/en/latest/evpn.html
    bridge link set dev vxlan1001 learning off
    ip link set up dev vxlan1001
  
  
    exit $?
ok: [l1] => 
  msg: |-
    vxlan configuration for l1
    =========================================
    interface vxlan 1
      vxlan source-interface Loopback0
      vxlan vlan 1000 vni 1000
      vxlan vlan 1001 vni 1001
ok: [spine] => 
  msg: |-
    vxlan configuration for spine
    =========================================
    interface vxlan 1
      vxlan source-interface Loopback0
      vxlan vlan 1000 vni 1000
      vxlan vlan 1001 vni 1001

TASK [Find configuration deployment deploy_script for vxlan] *******************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Deploy vxlan configuration] **********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/eos.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [eos_config: deploying vxlan from /home/pipi/net101/tools/netsim/ansible/templates/vxlan/eos.j2] ***
changed: [spine]
changed: [l1]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy vxlan config from /home/pipi/net101/tools/netsim/ansible/templates/vxlan/frr.j2] ***
changed: [l2]

TASK [run vtysh to import vxlan config from /home/pipi/net101/tools/netsim/ansible/templates/vxlan/frr.j2] ***
skipping: [l2]

TASK [Figure out whether to deploy the module evpn on current device] **********
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Find configuration template for evpn] ************************************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [l2] => 
  msg: |-
    evpn configuration for l2
    =========================================
    router bgp 65000
     address-family l2vpn evpn
      advertise-all-vni
      advertise-svi-ip
      advertise ipv4 unicast
  
    ! Configure explicit Route Targets and RD per L2 VNI; auto-derived differs
      vni 1001
       rd 10.0.0.6:1001
       route-target export 65000:1001
       route-target import 65000:1001
      exit-vni
      vni 1000
       rd 10.0.0.6:1000
       route-target export 65000:1000
       route-target import 65000:1000
      exit-vni
  
      neighbor 10.0.0.7 activate
      neighbor 10.0.0.7 soft-reconfiguration inbound
  
     exit-address-family
    !
  
    exit
  
    ! L3 VRF EVPN handling
    !
    do write
ok: [l1] => 
  msg: |-
    evpn configuration for l1
    =========================================
    !
    router bgp 65000
     address-family evpn
    !
      neighbor 10.0.0.7 activate
    !
     vlan 1001
      rd 10.0.0.5:1001
      route-target import 65000:1001
      route-target export 65000:1001
      redistribute learned
    !
     vlan 1000
      rd 10.0.0.5:1000
      route-target import 65000:1000
      route-target export 65000:1000
      redistribute learned
ok: [spine] => 
  msg: |-
    evpn configuration for spine
    =========================================
    !
    router bgp 65000
     address-family evpn
    !
      neighbor 10.0.0.5 activate
      neighbor 10.0.0.6 activate
    !
     vlan 1001
      rd 10.0.0.7:1001
      route-target import 65000:1001
      route-target export 65000:1001
      redistribute learned
    !
     vlan 1000
      rd 10.0.0.7:1000
      route-target import 65000:1000
      route-target export 65000:1000
      redistribute learned
    !
     vrf customer
      rd 65000:1
      route-target import evpn 65000:1
      route-target export evpn 65000:1
      redistribute connected

TASK [Find configuration deployment deploy_script for evpn] ********************
ok: [l2]
ok: [l1]
ok: [spine]

TASK [Deploy evpn configuration] ***********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/eos.yml for l1, spine
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for l2

TASK [eos_config: deploying evpn from /home/pipi/net101/tools/netsim/ansible/templates/evpn/eos.j2] ***
changed: [l1]
changed: [spine]

TASK [template] ****************************************************************
changed: [l2]

TASK [set_fact] ****************************************************************
ok: [l2]

TASK [run /tmp/config.sh to deploy evpn config from /home/pipi/net101/tools/netsim/ansible/templates/evpn/frr.j2] ***
skipping: [l2]

TASK [run vtysh to import evpn config from /home/pipi/net101/tools/netsim/ansible/templates/evpn/frr.j2] ***
changed: [l2]

PLAY [Deploy custom deployment templates] **************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
h1                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
h2                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
h3                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
h4                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
l1                         : ok=54   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
l2                         : ok=68   changed=15   unreachable=0    failed=0    skipped=9    rescued=0    ignored=0   
spine                      : ok=54   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   



The devices under test are a layer-2 leaf and a spine performing centralized
routing.

All hosts should be able to ping each other and all switch loopback IPs

Please note it might take a while for the lab to work due to STP learning
phase.

